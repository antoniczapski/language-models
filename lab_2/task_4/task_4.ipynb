{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\ProgramData\\Anaconda3\\envs\\university-masters\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from torch.nn import functional as F\n",
    "import random\n",
    "\n",
    "model_name = 'eryk-mazus/polka-1.1b'  # Updated model name to match initialization\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Generating for prefix: 'Obowiązuje on od' ===\n",
      "[DEBUG] Trying: 'Obowiązuje on od|:' (depth=1)\n",
      "[DEBUG] Trying: 'Obowiązuje on od:|2' (depth=2)\n",
      "[DEBUG] Trying: 'Obowiązuje on od:2|0' (depth=3)\n",
      "[DEBUG] Trying: 'Obowiązuje on od:20|1' (depth=4)\n",
      "[DEBUG] Trying: 'Obowiązuje on od:201|9' (depth=5)\n",
      "[DEBUG] Trying: 'Obowiązuje on od:2019|-' (depth=6)\n",
      "[DEBUG] Dead end. Backtracking from: 'Obowiązuje on od:2019-'\n",
      "[DEBUG] Backtracking from: 'Obowiązuje on od:2019|-'\n",
      "[DEBUG] Trying: 'Obowiązuje on od:2019|.' (depth=6)\n",
      "FINAL COMPLETION: 'Obowiązuje on od:2019.'\n",
      "\n",
      "=== Generating for prefix: 'Został zrodzony ze' ===\n",
      "[DEBUG] Trying: 'Został zrodzony ze|▁zł' (depth=1)\n",
      "[DEBUG] Trying: 'Został zrodzony ze zł|ota' (depth=2)\n",
      "[DEBUG] Trying: 'Został zrodzony ze złota|,' (depth=3)\n",
      "[DEBUG] Trying: 'Został zrodzony ze złota,|▁został' (depth=4)\n",
      "[DEBUG] Trying: 'Został zrodzony ze złota, został|▁z' (depth=5)\n",
      "[DEBUG] Trying: 'Został zrodzony ze złota, został z|rodz' (depth=6)\n",
      "[DEBUG] Trying: 'Został zrodzony ze złota, został zrodz|ony' (depth=7)\n",
      "[DEBUG] Trying: 'Został zrodzony ze złota, został zrodzony|▁z' (depth=8)\n",
      "[DEBUG] Trying: 'Został zrodzony ze złota, został zrodzony z|▁z' (depth=9)\n",
      "[DEBUG] Trying: 'Został zrodzony ze złota, został zrodzony z z|iem' (depth=10)\n",
      "[DEBUG] Trying: 'Został zrodzony ze złota, został zrodzony z ziem|i' (depth=11)\n",
      "[DEBUG] Trying: 'Został zrodzony ze złota, został zrodzony z ziemi|.' (depth=12)\n",
      "FINAL COMPLETION: 'Został zrodzony ze złota, został zrodzony z ziemi.'\n",
      "\n",
      "=== Generating for prefix: 'Po pierwsze, projekt' ===\n",
      "[DEBUG] Trying: 'Po pierwsze, projekt|owanie' (depth=1)\n",
      "[DEBUG] Trying: 'Po pierwsze, projektowanie|▁prz' (depth=2)\n",
      "[DEBUG] Trying: 'Po pierwsze, projektowanie prz|estr' (depth=3)\n",
      "[DEBUG] Dead end. Backtracking from: 'Po pierwsze, projektowanie przestr'\n",
      "[DEBUG] Backtracking from: 'Po pierwsze, projektowanie prz|estr'\n",
      "[DEBUG] Trying: 'Po pierwsze, projektowanie prz|em' (depth=3)\n",
      "[DEBUG] Trying: 'Po pierwsze, projektowanie przem|ys' (depth=4)\n",
      "[DEBUG] Trying: 'Po pierwsze, projektowanie przemys|ł' (depth=5)\n",
      "[DEBUG] Trying: 'Po pierwsze, projektowanie przemysł|owe' (depth=6)\n",
      "[DEBUG] Trying: 'Po pierwsze, projektowanie przemysłowe|▁-' (depth=7)\n",
      "[DEBUG] Trying: 'Po pierwsze, projektowanie przemysłowe -|▁projekt' (depth=8)\n",
      "[DEBUG] Trying: 'Po pierwsze, projektowanie przemysłowe - projekt|ant' (depth=9)\n",
      "[DEBUG] Trying: 'Po pierwsze, projektowanie przemysłowe - projektant|▁prz' (depth=10)\n",
      "[DEBUG] Dead end. Backtracking from: 'Po pierwsze, projektowanie przemysłowe - projektant prz'\n",
      "[DEBUG] Backtracking from: 'Po pierwsze, projektowanie przemysłowe - projektant|▁prz'\n",
      "[DEBUG] Trying: 'Po pierwsze, projektowanie przemysłowe - projektant|▁-' (depth=10)\n",
      "[DEBUG] Trying: 'Po pierwsze, projektowanie przemysłowe - projektant -|▁projekt' (depth=11)\n",
      "[DEBUG] Trying: 'Po pierwsze, projektowanie przemysłowe - projektant - projekt|anci' (depth=12)\n",
      "[DEBUG] Trying: 'Po pierwsze, projektowanie przemysłowe - projektant - projektanci|▁-' (depth=13)\n",
      "[DEBUG] Trying: 'Po pierwsze, projektowanie przemysłowe - projektant - projektanci -|▁projekt' (depth=14)\n",
      "[DEBUG] Trying: 'Po pierwsze, projektowanie przemysłowe - projektant - projektanci - projekt|ow' (depth=15)\n",
      "FINAL COMPLETION: 'Po pierwsze, projektowanie przemysłowe - projektant - projektanci - projektow.'\n",
      "\n",
      "=== Generating for prefix: 'Po Panthers przejechali' ===\n",
      "[DEBUG] Trying: 'Po Panthers przejechali|▁przez' (depth=1)\n",
      "[DEBUG] Trying: 'Po Panthers przejechali przez|▁park' (depth=2)\n",
      "[DEBUG] Trying: 'Po Panthers przejechali przez park|,' (depth=3)\n",
      "[DEBUG] Trying: 'Po Panthers przejechali przez park,|▁polic' (depth=4)\n",
      "[DEBUG] Trying: 'Po Panthers przejechali przez park, polic|ja' (depth=5)\n",
      "[DEBUG] Trying: 'Po Panthers przejechali przez park, policja|▁pos' (depth=6)\n",
      "[DEBUG] Trying: 'Po Panthers przejechali przez park, policja pos|zu' (depth=7)\n",
      "[DEBUG] Trying: 'Po Panthers przejechali przez park, policja poszu|kuje' (depth=8)\n",
      "[DEBUG] Trying: 'Po Panthers przejechali przez park, policja poszukuje|▁p' (depth=9)\n",
      "[DEBUG] Trying: 'Po Panthers przejechali przez park, policja poszukuje p|sa' (depth=10)\n",
      "[DEBUG] Trying: 'Po Panthers przejechali przez park, policja poszukuje psa|▁-' (depth=11)\n",
      "[DEBUG] Trying: 'Po Panthers przejechali przez park, policja poszukuje psa -|▁Portal' (depth=12)\n",
      "[DEBUG] Trying: 'Po Panthers przejechali przez park, policja poszukuje psa - Portal|▁P' (depth=13)\n",
      "[DEBUG] Dead end. Backtracking from: 'Po Panthers przejechali przez park, policja poszukuje psa - Portal P'\n",
      "[DEBUG] Backtracking from: 'Po Panthers przejechali przez park, policja poszukuje psa - Portal|▁P'\n",
      "[DEBUG] Trying: 'Po Panthers przejechali przez park, policja poszukuje psa - Portal|P' (depth=13)\n",
      "[DEBUG] Trying: 'Po Panthers przejechali przez park, policja poszukuje psa - PortalP|omor' (depth=14)\n",
      "[DEBUG] Dead end. Backtracking from: 'Po Panthers przejechali przez park, policja poszukuje psa - PortalPomor'\n",
      "[DEBUG] Backtracking from: 'Po Panthers przejechali przez park, policja poszukuje psa - PortalP|omor'\n",
      "[DEBUG] Trying: 'Po Panthers przejechali przez park, policja poszukuje psa - PortalP|is' (depth=14)\n",
      "[DEBUG] Trying: 'Po Panthers przejechali przez park, policja poszukuje psa - PortalPis|ar' (depth=15)\n",
      "FINAL COMPLETION: 'Po Panthers przejechali przez park, policja poszukuje psa - PortalPisar.'\n",
      "\n",
      "=== Generating for prefix: 'Duze dwusuwowe diesle' ===\n",
      "[DEBUG] Trying: 'Duze dwusuwowe diesle|▁-' (depth=1)\n",
      "[DEBUG] Trying: 'Duze dwusuwowe diesle -|▁D' (depth=2)\n",
      "[DEBUG] Trying: 'Duze dwusuwowe diesle - D|ział' (depth=3)\n",
      "[DEBUG] Trying: 'Duze dwusuwowe diesle - Dział|aj' (depth=4)\n",
      "[DEBUG] Trying: 'Duze dwusuwowe diesle - Działaj|L' (depth=5)\n",
      "[DEBUG] Trying: 'Duze dwusuwowe diesle - DziałajL|okal' (depth=6)\n",
      "[DEBUG] Trying: 'Duze dwusuwowe diesle - DziałajLokal|nie' (depth=7)\n",
      "[DEBUG] Trying: 'Duze dwusuwowe diesle - DziałajLokalnie|.pl' (depth=8)\n",
      "[DEBUG] Trying: 'Duze dwusuwowe diesle - DziałajLokalnie.pl|\\nD' (depth=9)\n",
      "[DEBUG] Trying: 'Duze dwusuwowe diesle - DziałajLokalnie.pl\\nD|u' (depth=10)\n",
      "[DEBUG] Trying: 'Duze dwusuwowe diesle - DziałajLokalnie.pl\\nDu|ze' (depth=11)\n",
      "[DEBUG] Dead end. Backtracking from: 'Duze dwusuwowe diesle - DziałajLokalnie.pl\\nDuze'\n",
      "[DEBUG] Backtracking from: 'Duze dwusuwowe diesle - DziałajLokalnie.pl\\nDu|ze'\n",
      "[DEBUG] Backtracking from: 'Duze dwusuwowe diesle - DziałajLokalnie.pl\\nD|u'\n",
      "[DEBUG] Trying: 'Duze dwusuwowe diesle - DziałajLokalnie.pl\\nD|uży' (depth=10)\n",
      "[DEBUG] Trying: 'Duze dwusuwowe diesle - DziałajLokalnie.pl\\nDuży|▁dw' (depth=11)\n",
      "[DEBUG] Dead end. Backtracking from: 'Duze dwusuwowe diesle - DziałajLokalnie.pl\\nDuży dw'\n",
      "[DEBUG] Backtracking from: 'Duze dwusuwowe diesle - DziałajLokalnie.pl\\nDuży|▁dw'\n",
      "[DEBUG] Trying: 'Duze dwusuwowe diesle - DziałajLokalnie.pl\\nDuży|▁dies' (depth=11)\n",
      "[DEBUG] Trying: 'Duze dwusuwowe diesle - DziałajLokalnie.pl\\nDuży dies|el' (depth=12)\n",
      "[DEBUG] Trying: 'Duze dwusuwowe diesle - DziałajLokalnie.pl\\nDuży diesel|,' (depth=13)\n",
      "[DEBUG] Trying: 'Duze dwusuwowe diesle - DziałajLokalnie.pl\\nDuży diesel,|▁du' (depth=14)\n",
      "[DEBUG] Trying: 'Duze dwusuwowe diesle - DziałajLokalnie.pl\\nDuży diesel, du|że' (depth=15)\n",
      "FINAL COMPLETION: 'Duze dwusuwowe diesle - DziałajLokalnie.pl\\nDuży diesel, duże.'\n",
      "\n",
      "=== Generating for prefix: 'Niestety, nikt nie' ===\n",
      "[DEBUG] Trying: 'Niestety, nikt nie|▁nap' (depth=1)\n",
      "[DEBUG] Trying: 'Niestety, nikt nie nap|is' (depth=2)\n",
      "[DEBUG] Trying: 'Niestety, nikt nie napis|ał' (depth=3)\n",
      "[DEBUG] Trying: 'Niestety, nikt nie napisał|,' (depth=4)\n",
      "[DEBUG] Trying: 'Niestety, nikt nie napisał,|▁na' (depth=5)\n",
      "[DEBUG] Trying: 'Niestety, nikt nie napisał, na|wet' (depth=6)\n",
      "[DEBUG] Trying: 'Niestety, nikt nie napisał, nawet|▁na' (depth=7)\n",
      "[DEBUG] Trying: 'Niestety, nikt nie napisał, nawet na|▁nas' (depth=8)\n",
      "[DEBUG] Trying: 'Niestety, nikt nie napisał, nawet na nas|zej' (depth=9)\n",
      "[DEBUG] Dead end. Backtracking from: 'Niestety, nikt nie napisał, nawet na naszej'\n",
      "[DEBUG] Backtracking from: 'Niestety, nikt nie napisał, nawet na nas|zej'\n",
      "[DEBUG] Trying: 'Niestety, nikt nie napisał, nawet na nas|zym' (depth=9)\n",
      "[DEBUG] Dead end. Backtracking from: 'Niestety, nikt nie napisał, nawet na naszym'\n",
      "[DEBUG] Backtracking from: 'Niestety, nikt nie napisał, nawet na nas|zym'\n",
      "[DEBUG] Trying: 'Niestety, nikt nie napisał, nawet na nas|zych' (depth=9)\n",
      "[DEBUG] Dead end. Backtracking from: 'Niestety, nikt nie napisał, nawet na naszych'\n",
      "[DEBUG] Backtracking from: 'Niestety, nikt nie napisał, nawet na nas|zych'\n",
      "[DEBUG] Trying: 'Niestety, nikt nie napisał, nawet na nas|z' (depth=9)\n",
      "[DEBUG] Trying: 'Niestety, nikt nie napisał, nawet na nasz|ego' (depth=10)\n",
      "[DEBUG] Dead end. Backtracking from: 'Niestety, nikt nie napisał, nawet na naszego'\n",
      "[DEBUG] Backtracking from: 'Niestety, nikt nie napisał, nawet na nasz|ego'\n",
      "[DEBUG] Trying: 'Niestety, nikt nie napisał, nawet na nasz|ym' (depth=10)\n",
      "[DEBUG] Dead end. Backtracking from: 'Niestety, nikt nie napisał, nawet na naszym'\n",
      "[DEBUG] Backtracking from: 'Niestety, nikt nie napisał, nawet na nasz|ym'\n",
      "[DEBUG] Trying: 'Niestety, nikt nie napisał, nawet na nasz|ch' (depth=10)\n",
      "[DEBUG] Dead end. Backtracking from: 'Niestety, nikt nie napisał, nawet na naszch'\n",
      "[DEBUG] Backtracking from: 'Niestety, nikt nie napisał, nawet na nasz|ch'\n",
      "[DEBUG] Trying: 'Niestety, nikt nie napisał, nawet na nasz|.' (depth=10)\n",
      "FINAL COMPLETION: 'Niestety, nikt nie napisał, nawet na nasz.'\n",
      "\n",
      "=== Generating for prefix: 'Pani poseł, proszę' ===\n",
      "[DEBUG] Trying: 'Pani poseł, proszę|▁pow' (depth=1)\n",
      "[DEBUG] Trying: 'Pani poseł, proszę pow|ied' (depth=2)\n",
      "[DEBUG] Dead end. Backtracking from: 'Pani poseł, proszę powied'\n",
      "[DEBUG] Backtracking from: 'Pani poseł, proszę pow|ied'\n",
      "[DEBUG] Trying: 'Pani poseł, proszę pow|oła' (depth=2)\n",
      "[DEBUG] Trying: 'Pani poseł, proszę powoła|ć' (depth=3)\n",
      "[DEBUG] Trying: 'Pani poseł, proszę powołać|▁peł' (depth=4)\n",
      "[DEBUG] Trying: 'Pani poseł, proszę powołać peł|nom' (depth=5)\n",
      "[DEBUG] Dead end. Backtracking from: 'Pani poseł, proszę powołać pełnom'\n",
      "[DEBUG] Backtracking from: 'Pani poseł, proszę powołać peł|nom'\n",
      "[DEBUG] Trying: 'Pani poseł, proszę powołać peł|ną' (depth=5)\n",
      "[DEBUG] Trying: 'Pani poseł, proszę powołać pełną|,' (depth=6)\n",
      "[DEBUG] Trying: 'Pani poseł, proszę powołać pełną,|▁profesjonal' (depth=7)\n",
      "[DEBUG] Dead end. Backtracking from: 'Pani poseł, proszę powołać pełną, profesjonal'\n",
      "[DEBUG] Backtracking from: 'Pani poseł, proszę powołać pełną,|▁profesjonal'\n",
      "[DEBUG] Trying: 'Pani poseł, proszę powołać pełną,|▁praw' (depth=7)\n",
      "[DEBUG] Trying: 'Pani poseł, proszę powołać pełną, praw|dziw' (depth=8)\n",
      "[DEBUG] Trying: 'Pani poseł, proszę powołać pełną, prawdziw|ą' (depth=9)\n",
      "[DEBUG] Dead end. Backtracking from: 'Pani poseł, proszę powołać pełną, prawdziwą'\n",
      "[DEBUG] Backtracking from: 'Pani poseł, proszę powołać pełną, prawdziw|ą'\n",
      "[DEBUG] Backtracking from: 'Pani poseł, proszę powołać pełną, praw|dziw'\n",
      "[DEBUG] Trying: 'Pani poseł, proszę powołać pełną, praw|or' (depth=8)\n",
      "[DEBUG] Trying: 'Pani poseł, proszę powołać pełną, prawor|zą' (depth=9)\n",
      "[DEBUG] Dead end. Backtracking from: 'Pani poseł, proszę powołać pełną, praworzą'\n",
      "[DEBUG] Backtracking from: 'Pani poseł, proszę powołać pełną, prawor|zą'\n",
      "[DEBUG] Trying: 'Pani poseł, proszę powołać pełną, prawor|ząd' (depth=9)\n",
      "[DEBUG] Trying: 'Pani poseł, proszę powołać pełną, praworząd|na' (depth=10)\n",
      "[DEBUG] Trying: 'Pani poseł, proszę powołać pełną, praworządna|▁parlament' (depth=11)\n",
      "[DEBUG] Trying: 'Pani poseł, proszę powołać pełną, praworządna parlament|arn' (depth=12)\n",
      "[DEBUG] Trying: 'Pani poseł, proszę powołać pełną, praworządna parlamentarn|ą' (depth=13)\n",
      "[DEBUG] Trying: 'Pani poseł, proszę powołać pełną, praworządna parlamentarną|▁pod' (depth=14)\n",
      "[DEBUG] Dead end. Backtracking from: 'Pani poseł, proszę powołać pełną, praworządna parlamentarną pod'\n",
      "[DEBUG] Backtracking from: 'Pani poseł, proszę powołać pełną, praworządna parlamentarną|▁pod'\n",
      "[DEBUG] Backtracking from: 'Pani poseł, proszę powołać pełną, praworządna parlamentarn|ą'\n",
      "[DEBUG] Backtracking from: 'Pani poseł, proszę powołać pełną, praworządna parlament|arn'\n",
      "[DEBUG] Trying: 'Pani poseł, proszę powołać pełną, praworządna parlament|ar' (depth=12)\n",
      "[DEBUG] Trying: 'Pani poseł, proszę powołać pełną, praworządna parlamentar|no-' (depth=13)\n",
      "[DEBUG] Trying: 'Pani poseł, proszę powołać pełną, praworządna parlamentarno-|admin' (depth=14)\n",
      "[DEBUG] Dead end. Backtracking from: 'Pani poseł, proszę powołać pełną, praworządna parlamentarno-admin'\n",
      "[DEBUG] Backtracking from: 'Pani poseł, proszę powołać pełną, praworządna parlamentarno-|admin'\n",
      "[DEBUG] Trying: 'Pani poseł, proszę powołać pełną, praworządna parlamentarno-|g' (depth=14)\n",
      "[DEBUG] Trying: 'Pani poseł, proszę powołać pełną, praworządna parlamentarno-g|ab' (depth=15)\n",
      "FINAL COMPLETION: 'Pani poseł, proszę powołać pełną, praworządna parlamentarno-gab.'\n",
      "\n",
      "=== Generating for prefix: 'Proszę państwa, po' ===\n",
      "[DEBUG] Trying: 'Proszę państwa, po|▁prostu' (depth=1)\n",
      "[DEBUG] Trying: 'Proszę państwa, po prostu|▁prz' (depth=2)\n",
      "[DEBUG] Trying: 'Proszę państwa, po prostu prz|ec' (depth=3)\n",
      "[DEBUG] Trying: 'Proszę państwa, po prostu przec|zy' (depth=4)\n",
      "[DEBUG] Trying: 'Proszę państwa, po prostu przeczy|taj' (depth=5)\n",
      "[DEBUG] Trying: 'Proszę państwa, po prostu przeczytaj|cie' (depth=6)\n",
      "[DEBUG] Trying: 'Proszę państwa, po prostu przeczytajcie|!' (depth=7)\n",
      "FINAL COMPLETION: 'Proszę państwa, po prostu przeczytajcie!'\n",
      "\n",
      "=== Generating for prefix: 'Proszę pana posła' ===\n",
      "[DEBUG] Trying: 'Proszę pana posła|▁-' (depth=1)\n",
      "[DEBUG] Trying: 'Proszę pana posła -|▁P' (depth=2)\n",
      "[DEBUG] Trying: 'Proszę pana posła - P|uls' (depth=3)\n",
      "[DEBUG] Trying: 'Proszę pana posła - Puls|▁Pod' (depth=4)\n",
      "[DEBUG] Trying: 'Proszę pana posła - Puls Pod|kar' (depth=5)\n",
      "[DEBUG] Trying: 'Proszę pana posła - Puls Podkar|p' (depth=6)\n",
      "[DEBUG] Dead end. Backtracking from: 'Proszę pana posła - Puls Podkarp'\n",
      "[DEBUG] Backtracking from: 'Proszę pana posła - Puls Podkar|p'\n",
      "[DEBUG] Backtracking from: 'Proszę pana posła - Puls Pod|kar'\n",
      "[DEBUG] Trying: 'Proszę pana posła - Puls Pod|las' (depth=5)\n",
      "[DEBUG] Dead end. Backtracking from: 'Proszę pana posła - Puls Podlas'\n",
      "[DEBUG] Backtracking from: 'Proszę pana posła - Puls Pod|las'\n",
      "[DEBUG] Trying: 'Proszę pana posła - Puls Pod|l' (depth=5)\n",
      "[DEBUG] Dead end. Backtracking from: 'Proszę pana posła - Puls Podl'\n",
      "[DEBUG] Backtracking from: 'Proszę pana posła - Puls Pod|l'\n",
      "[DEBUG] Trying: 'Proszę pana posła - Puls Pod|bes' (depth=5)\n",
      "[DEBUG] Dead end. Backtracking from: 'Proszę pana posła - Puls Podbes'\n",
      "[DEBUG] Backtracking from: 'Proszę pana posła - Puls Pod|bes'\n",
      "[DEBUG] Trying: 'Proszę pana posła - Puls Pod|w' (depth=5)\n",
      "[DEBUG] Trying: 'Proszę pana posła - Puls Podw|ars' (depth=6)\n",
      "[DEBUG] Dead end. Backtracking from: 'Proszę pana posła - Puls Podwars'\n",
      "[DEBUG] Backtracking from: 'Proszę pana posła - Puls Podw|ars'\n",
      "[DEBUG] Trying: 'Proszę pana posła - Puls Podw|aw' (depth=6)\n",
      "[DEBUG] Dead end. Backtracking from: 'Proszę pana posła - Puls Podwaw'\n",
      "[DEBUG] Backtracking from: 'Proszę pana posła - Puls Podw|aw'\n",
      "[DEBUG] Trying: 'Proszę pana posła - Puls Podw|ale' (depth=6)\n",
      "[DEBUG] Trying: 'Proszę pana posła - Puls Podwale|\\n' (depth=7)\n",
      "[DEBUG] Trying: 'Proszę pana posła - Puls Podwale\\n|Str' (depth=8)\n",
      "[DEBUG] Trying: 'Proszę pana posła - Puls Podwale\\nStr|ona' (depth=9)\n",
      "[DEBUG] Dead end. Backtracking from: 'Proszę pana posła - Puls Podwale\\nStrona'\n",
      "[DEBUG] Backtracking from: 'Proszę pana posła - Puls Podwale\\nStr|ona'\n",
      "[DEBUG] Trying: 'Proszę pana posła - Puls Podwale\\nStr|.' (depth=9)\n",
      "FINAL COMPLETION: 'Proszę pana posła - Puls Podwale\\nStr.'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "# Invert vocabulary to quickly map IDs -> tokens\n",
    "vocab = tokenizer.get_vocab()\n",
    "id_to_token = {v: k for k, v in vocab.items()}\n",
    "\n",
    "def strip_special(token: str) -> str:\n",
    "    \"\"\"\n",
    "    Removes special SentencePiece characters like '▁' from the start of tokens.\n",
    "    \"\"\"\n",
    "    return token.lstrip(\"▁\")\n",
    "\n",
    "def starts_with_letter(token: str, letter: str) -> bool:\n",
    "    \"\"\"\n",
    "    Returns True if 'token' (after removing special chars) starts with the given letter.\n",
    "    \"\"\"\n",
    "    # if equal to one special token, return False\n",
    "    if token == '▁':\n",
    "        return False\n",
    "    # punctuation is ok\n",
    "    if token[0] == '▁' and len(token) == 2 and token[1] in string.punctuation:\n",
    "        return True\n",
    "    for sub_word in token.split('▁')[1:]:\n",
    "        if sub_word and sub_word[0].lower() != letter:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def middle_of_the_word(token: str) -> bool:\n",
    "    \"\"\"\n",
    "    Returns True if the token does not start with special character.\n",
    "    \"\"\"\n",
    "    return '▁' not in token\n",
    "\n",
    "def top_k_top_p_filtering(logits, top_k=50, top_p=0.9):\n",
    "    \"\"\"\n",
    "    Filters a distribution of logits using top-k and nucleus (top-p) filtering.\n",
    "    Sets probabilities of tokens outside the top-k or top-p to -inf.\n",
    "    \"\"\"\n",
    "    # Apply top-k\n",
    "    if top_k > 0:\n",
    "        # get top_k indices\n",
    "        values_to_keep, _ = torch.topk(logits, top_k)\n",
    "        min_value_to_keep = values_to_keep[-1]\n",
    "        logits[logits < min_value_to_keep] = float('-inf')\n",
    "    \n",
    "    # Apply top-p (nucleus) filtering\n",
    "    sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
    "    cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "    # mask out tokens beyond top_p\n",
    "    sorted_indices_to_remove = sorted_indices[cumulative_probs > top_p]\n",
    "    logits[sorted_indices_to_remove] = float('-inf')\n",
    "    \n",
    "    # # print how many is left\n",
    "    # print(f\"Left: {len(logits[logits != float('-inf')])}\")\n",
    "    \n",
    "    return logits\n",
    "\n",
    "def get_candidates(prefix: str, letter: str, top_k_val=50, top_p_val=0.9):\n",
    "    \"\"\"\n",
    "    Get candidate tokens (string, probability) for the next position,\n",
    "    filtered by top-k/top-p, then by first-letter constraint.\n",
    "    \"\"\"\n",
    "    input_ids = tokenizer(prefix, return_tensors='pt')['input_ids'].to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids)\n",
    "    \n",
    "    next_logits = outputs.logits[0, -1, :]\n",
    "    \n",
    "    # Optionally adjust logits (e.g., temperature)\n",
    "    # temperature = 1.0\n",
    "    # next_logits = next_logits / temperature\n",
    "    \n",
    "    # top-k / top-p filtering\n",
    "    filtered_logits = top_k_top_p_filtering(next_logits.clone(),\n",
    "                                           top_k=top_k_val,\n",
    "                                           top_p=top_p_val)\n",
    "    probs = F.softmax(filtered_logits, dim=-1)\n",
    "    \n",
    "    # Collect valid candidates\n",
    "    candidates = []\n",
    "    for token_id in range(probs.shape[0]):\n",
    "        p = probs[token_id].item()\n",
    "        if p > 0:\n",
    "            token_str = id_to_token[token_id]\n",
    "            if middle_of_the_word(token_str) or starts_with_letter(token_str, letter):\n",
    "                # # replace '▁' => ' ' for nice spacing\n",
    "                # display_str = token_str.replace('▁', ' ')\n",
    "                # display_str = f'{token_str}|'\n",
    "                candidates.append((token_str, p))\n",
    "    \n",
    "    # sort descending by probability\n",
    "    candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "    return candidates\n",
    "\n",
    "def backtrack_generation(\n",
    "    prefix: str, \n",
    "    letter: str,\n",
    "    depth: int,\n",
    "    max_depth: int,\n",
    "    used_tokens: set,\n",
    "    debug_mode: bool\n",
    "):\n",
    "    \"\"\"\n",
    "    Recursive function that tries to append one token at a time.\n",
    "    If we cannot find a valid token (dead end), we backtrack.\n",
    "\n",
    "    :param prefix: Current text.\n",
    "    :param letter: The designated letter for each next token.\n",
    "    :param depth: Current recursion depth (number of tokens added so far).\n",
    "    :param max_depth: Maximum tokens to generate.\n",
    "    :param used_tokens: A set of tokens we have used so far (for repetition avoidance).\n",
    "    :param debug_mode: Whether to print debug messages during backtracking.\n",
    "    :return: Completed string if successful, or None if no solution found.\n",
    "    \"\"\"\n",
    "    # If we've reached a sentence terminator, you could choose to stop here as success:\n",
    "    if any(prefix.endswith(p) for p in ['.', '!', '?']):\n",
    "        return prefix  # success\n",
    "    \n",
    "    if depth >= max_depth:\n",
    "        # Reached maximum length\n",
    "        return prefix  # success - or None if you require punctuation end\n",
    "    \n",
    "    # Gather next candidates\n",
    "    candidates = get_candidates(prefix, letter, top_k_val=30, top_p_val=0.99)\n",
    "    # Optionally filter out tokens we've used (simple repetition avoidance)\n",
    "    # (This might be overly strict in some scenarios.)\n",
    "    filtered = [(t, p) for (t, p) in candidates if t not in used_tokens]\n",
    "    \n",
    "    # argsort by probability, start from the highest\n",
    "    filtered.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    if not filtered:\n",
    "        # No valid tokens => Dead end, must backtrack\n",
    "        if debug_mode:\n",
    "            print(f\"[DEBUG] Dead end. Backtracking from: '{prefix}'\")\n",
    "        return None\n",
    "    \n",
    "    # We will try candidates from highest to lowest probability\n",
    "    # or you can randomize them; for demonstration let's do high->low\n",
    "    for token_str, prob in filtered:\n",
    "        new_prefix_raw = prefix + f'|{token_str}'\n",
    "        # Add token to used tokens (if you want to avoid immediate repetition)\n",
    "        \n",
    "        token = token_str.replace('▁', ' ')\n",
    "\n",
    "        # Extend prefix with this token\n",
    "        new_prefix = prefix + token\n",
    "\n",
    "        new_used = used_tokens.copy()\n",
    "        new_used.add(token)\n",
    "        \n",
    "        if debug_mode:\n",
    "            print(f\"[DEBUG] Trying: '{new_prefix_raw}' (depth={depth+1})\")\n",
    "        \n",
    "        result = backtrack_generation(\n",
    "            prefix=new_prefix,\n",
    "            letter=letter,\n",
    "            depth=depth+1,\n",
    "            max_depth=max_depth,\n",
    "            used_tokens=new_used,\n",
    "            debug_mode=debug_mode\n",
    "        )\n",
    "        \n",
    "        if result is not None:\n",
    "            # Found a valid completion from here on\n",
    "            return result\n",
    "        else:\n",
    "            # This candidate eventually led to a dead end, so we must backtrack\n",
    "            if debug_mode:\n",
    "                print(f\"[DEBUG] Backtracking from: '{new_prefix_raw}'\")\n",
    "    \n",
    "    # If we exhausted all candidates, we must backtrack further\n",
    "    return None\n",
    "\n",
    "def generate_sentence_with_backtracking(prefix, max_len=15, debug_mode=False):\n",
    "    \"\"\"\n",
    "    Wrapper that calls the recursive backtracking function.\n",
    "    \"\"\"\n",
    "    # The letter is the first letter of the prefix (lowercased).\n",
    "    # If you want a different letter, you can pass it explicitly.\n",
    "    cleaned_prefix = prefix.strip()\n",
    "    if not cleaned_prefix:\n",
    "        raise ValueError(\"Prefix cannot be empty.\")\n",
    "    \n",
    "    letter = cleaned_prefix[0].lower()\n",
    "    used_tokens = set()  # to optionally avoid immediate re-use of the same token\n",
    "    completed = backtrack_generation(\n",
    "        prefix=prefix,\n",
    "        letter=letter,\n",
    "        depth=0,\n",
    "        max_depth=max_len,\n",
    "        used_tokens=used_tokens,\n",
    "        debug_mode=debug_mode\n",
    "    )\n",
    "    # If you want to ensure the final text ends with punctuation, you can add logic here:\n",
    "    if completed is not None and not any(completed.endswith(p) for p in ['.', '!', '?']):\n",
    "        # Optionally add a period or do further checks\n",
    "        completed += \".\"\n",
    "    return completed\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# EXAMPLE USAGE\n",
    "# -------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    start_txts = [\n",
    "        \"Obowiązuje on od\",\n",
    "        \"Został zrodzony ze\",\n",
    "        \"Po pierwsze, projekt\",\n",
    "        \"Po Panthers przejechali\",\n",
    "        \"Duze dwusuwowe diesle\",\n",
    "        \"Niestety, nikt nie\",\n",
    "        \"Pani poseł, proszę\",\n",
    "        \"Proszę państwa, po\",\n",
    "        \"Proszę pana posła\"\n",
    "    ]\n",
    "    \n",
    "    for start_txt in start_txts:\n",
    "        print(f\"=== Generating for prefix: '{start_txt}' ===\")\n",
    "        # Try debug_mode=True to see backtracking steps\n",
    "        completion = generate_sentence_with_backtracking(start_txt, max_len=15, debug_mode=True)\n",
    "        print(f\"FINAL COMPLETION: '{completion}'\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Generating for prefix: 'Obowiązuje on od' ===\n",
      "FINAL COMPLETION: 'Obowiązuje on od:2019.'\n",
      "\n",
      "=== Generating for prefix: 'Został zrodzony ze' ===\n",
      "FINAL COMPLETION: 'Został zrodzony ze złota, został zrodzony z ziemi.'\n",
      "\n",
      "=== Generating for prefix: 'Po pierwsze, projekt' ===\n",
      "FINAL COMPLETION: 'Po pierwsze, projektowanie przemysłowe - projektant - projektanci - projektow.'\n",
      "\n",
      "=== Generating for prefix: 'Po Panthers przejechali' ===\n",
      "FINAL COMPLETION: 'Po Panthers przejechali przez park, policja poszukuje psa - PortalPisar.'\n",
      "\n",
      "=== Generating for prefix: 'Duze dwusuwowe diesle' ===\n",
      "FINAL COMPLETION: 'Duze dwusuwowe diesle - DziałajLokalnie.pl\\nDuży diesel, duże.'\n",
      "\n",
      "=== Generating for prefix: 'Niestety, nikt nie' ===\n",
      "FINAL COMPLETION: 'Niestety, nikt nie napisał, nawet na nasz.'\n",
      "\n",
      "=== Generating for prefix: 'Pani poseł, proszę' ===\n",
      "FINAL COMPLETION: 'Pani poseł, proszę powołać pełną, praworządna parlamentarno-gab.'\n",
      "\n",
      "=== Generating for prefix: 'Proszę państwa, po' ===\n",
      "FINAL COMPLETION: 'Proszę państwa, po prostu przeczytajcie!'\n",
      "\n",
      "=== Generating for prefix: 'Proszę pana posła' ===\n",
      "FINAL COMPLETION: 'Proszę pana posła - Puls Podwale\\nStr.'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_txts = [\n",
    "    \"Obowiązuje on od\",\n",
    "    \"Został zrodzony ze\",\n",
    "    \"Po pierwsze, projekt\",\n",
    "    \"Po Panthers przejechali\",\n",
    "    \"Duze dwusuwowe diesle\",\n",
    "    \"Niestety, nikt nie\",\n",
    "    \"Pani poseł, proszę\",\n",
    "    \"Proszę państwa, po\",\n",
    "    \"Proszę pana posła\"\n",
    "]\n",
    "\n",
    "for start_txt in start_txts:\n",
    "    print(f\"=== Generating for prefix: '{start_txt}' ===\")\n",
    "    # Try debug_mode=True to see backtracking steps\n",
    "    completion = generate_sentence_with_backtracking(start_txt, max_len=15, debug_mode=False)\n",
    "    print(f\"FINAL COMPLETION: '{completion}'\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: fb30f72b-4198-409c-9cc7-ec852d30a1b4)')' thrown while requesting HEAD https://huggingface.co/eryk-mazus/polka-1.1b/resolve/main/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Generating for prefix: 'Obowiązuje on od' ===\n",
      "FINAL COMPLETION: 'Obowiązuje on od:2019.'\n",
      "\n",
      "Generation Tree:\n",
      "└── :\n",
      "    └── 2\n",
      "        └── 0\n",
      "            └── 1\n",
      "                └── 9\n",
      "                    ├── -\n",
      "                    │   └── __dead_end__\n",
      "                    └── .\n",
      "\n",
      "================================================================================\n",
      "\n",
      "=== Generating for prefix: 'Został zrodzony ze' ===\n",
      "FINAL COMPLETION: 'Został zrodzony ze złota, został zrodzony z ziemi.'\n",
      "\n",
      "Generation Tree:\n",
      "└── ▁zł\n",
      "    └── ota\n",
      "        └── ,\n",
      "            └── ▁został\n",
      "                └── ▁z\n",
      "                    └── rodz\n",
      "                        └── ony\n",
      "                            └── ▁z\n",
      "                                └── ▁z\n",
      "                                    └── iem\n",
      "                                        └── i\n",
      "                                            └── .\n",
      "\n",
      "================================================================================\n",
      "\n",
      "=== Generating for prefix: 'Po pierwsze, projekt' ===\n",
      "FINAL COMPLETION: 'Po pierwsze, projektowanie przemysłowe - projektant - projektanci - projektow.'\n",
      "\n",
      "Generation Tree:\n",
      "└── owanie\n",
      "    └── ▁prz\n",
      "        ├── estr\n",
      "        │   └── __dead_end__\n",
      "        └── em\n",
      "            └── ys\n",
      "                └── ł\n",
      "                    └── owe\n",
      "                        └── ▁-\n",
      "                            └── ▁projekt\n",
      "                                └── ant\n",
      "                                    ├── ▁prz\n",
      "                                    │   └── __dead_end__\n",
      "                                    └── ▁-\n",
      "                                        └── ▁projekt\n",
      "                                            └── anci\n",
      "                                                └── ▁-\n",
      "                                                    └── ▁projekt\n",
      "                                                        └── ow\n",
      "\n",
      "================================================================================\n",
      "\n",
      "=== Generating for prefix: 'Po Panthers przejechali' ===\n",
      "FINAL COMPLETION: 'Po Panthers przejechali przez park, policja poszukuje psa - PortalPisar.'\n",
      "\n",
      "Generation Tree:\n",
      "└── ▁przez\n",
      "    └── ▁park\n",
      "        └── ,\n",
      "            └── ▁polic\n",
      "                └── ja\n",
      "                    └── ▁pos\n",
      "                        └── zu\n",
      "                            └── kuje\n",
      "                                └── ▁p\n",
      "                                    └── sa\n",
      "                                        └── ▁-\n",
      "                                            └── ▁Portal\n",
      "                                                ├── ▁P\n",
      "                                                │   └── __dead_end__\n",
      "                                                └── P\n",
      "                                                    ├── omor\n",
      "                                                    │   └── __dead_end__\n",
      "                                                    └── is\n",
      "                                                        └── ar\n",
      "\n",
      "================================================================================\n",
      "\n",
      "=== Generating for prefix: 'Duze dwusuwowe diesle' ===\n",
      "FINAL COMPLETION: 'Duze dwusuwowe diesle - DziałajLokalnie.pl\\nDuży diesel, duże.'\n",
      "\n",
      "Generation Tree:\n",
      "└── ▁-\n",
      "    └── ▁D\n",
      "        └── ział\n",
      "            └── aj\n",
      "                └── L\n",
      "                    └── okal\n",
      "                        └── nie\n",
      "                            └── .pl\n",
      "                                └── \\nD\n",
      "                                    ├── u\n",
      "                                    │   ├── ze\n",
      "                                    │   │   └── __dead_end__\n",
      "                                    │   └── __dead_end__\n",
      "                                    └── uży\n",
      "                                        ├── ▁dw\n",
      "                                        │   └── __dead_end__\n",
      "                                        └── ▁dies\n",
      "                                            └── el\n",
      "                                                └── ,\n",
      "                                                    └── ▁du\n",
      "                                                        └── że\n",
      "\n",
      "================================================================================\n",
      "\n",
      "=== Generating for prefix: 'Niestety, nikt nie' ===\n",
      "FINAL COMPLETION: 'Niestety, nikt nie napisał, nawet na nasz.'\n",
      "\n",
      "Generation Tree:\n",
      "└── ▁nap\n",
      "    └── is\n",
      "        └── ał\n",
      "            └── ,\n",
      "                └── ▁na\n",
      "                    └── wet\n",
      "                        └── ▁na\n",
      "                            └── ▁nas\n",
      "                                ├── zej\n",
      "                                │   └── __dead_end__\n",
      "                                ├── zym\n",
      "                                │   └── __dead_end__\n",
      "                                ├── zych\n",
      "                                │   └── __dead_end__\n",
      "                                └── z\n",
      "                                    ├── ego\n",
      "                                    │   └── __dead_end__\n",
      "                                    ├── ym\n",
      "                                    │   └── __dead_end__\n",
      "                                    ├── ch\n",
      "                                    │   └── __dead_end__\n",
      "                                    └── .\n",
      "\n",
      "================================================================================\n",
      "\n",
      "=== Generating for prefix: 'Pani poseł, proszę' ===\n",
      "FINAL COMPLETION: 'Pani poseł, proszę powołać pełną, praworządna parlamentarno-gab.'\n",
      "\n",
      "Generation Tree:\n",
      "└── ▁pow\n",
      "    ├── ied\n",
      "    │   └── __dead_end__\n",
      "    └── oła\n",
      "        └── ć\n",
      "            └── ▁peł\n",
      "                ├── nom\n",
      "                │   └── __dead_end__\n",
      "                └── ną\n",
      "                    └── ,\n",
      "                        ├── ▁profesjonal\n",
      "                        │   └── __dead_end__\n",
      "                        └── ▁praw\n",
      "                            ├── dziw\n",
      "                            │   ├── ą\n",
      "                            │   │   └── __dead_end__\n",
      "                            │   └── __dead_end__\n",
      "                            └── or\n",
      "                                ├── zą\n",
      "                                │   └── __dead_end__\n",
      "                                └── ząd\n",
      "                                    └── na\n",
      "                                        └── ▁parlament\n",
      "                                            ├── arn\n",
      "                                            │   ├── ą\n",
      "                                            │   │   ├── ▁pod\n",
      "                                            │   │   │   └── __dead_end__\n",
      "                                            │   │   └── __dead_end__\n",
      "                                            │   └── __dead_end__\n",
      "                                            └── ar\n",
      "                                                └── no-\n",
      "                                                    ├── admin\n",
      "                                                    │   └── __dead_end__\n",
      "                                                    └── g\n",
      "                                                        └── ab\n",
      "\n",
      "================================================================================\n",
      "\n",
      "=== Generating for prefix: 'Proszę państwa, po' ===\n",
      "FINAL COMPLETION: 'Proszę państwa, po prostu przeczytajcie!'\n",
      "\n",
      "Generation Tree:\n",
      "└── ▁prostu\n",
      "    └── ▁prz\n",
      "        └── ec\n",
      "            └── zy\n",
      "                └── taj\n",
      "                    └── cie\n",
      "                        └── !\n",
      "\n",
      "================================================================================\n",
      "\n",
      "=== Generating for prefix: 'Proszę pana posła' ===\n",
      "FINAL COMPLETION: 'Proszę pana posła - Puls Podwale\\nStr.'\n",
      "\n",
      "Generation Tree:\n",
      "└── ▁-\n",
      "    └── ▁P\n",
      "        └── uls\n",
      "            └── ▁Pod\n",
      "                ├── kar\n",
      "                │   ├── p\n",
      "                │   │   └── __dead_end__\n",
      "                │   └── __dead_end__\n",
      "                ├── las\n",
      "                │   └── __dead_end__\n",
      "                ├── l\n",
      "                │   └── __dead_end__\n",
      "                ├── bes\n",
      "                │   └── __dead_end__\n",
      "                └── w\n",
      "                    ├── ars\n",
      "                    │   └── __dead_end__\n",
      "                    ├── aw\n",
      "                    │   └── __dead_end__\n",
      "                    └── ale\n",
      "                        └── \\n\n",
      "                            └── Str\n",
      "                                ├── ona\n",
      "                                │   └── __dead_end__\n",
      "                                └── .\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from torch.nn import functional as F\n",
    "import random\n",
    "import string\n",
    "\n",
    "# Initialize the model and tokenizer\n",
    "model_name = \"eryk-mazus/polka-1.1b\"  # Example model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "\n",
    "# Invert vocabulary to quickly map IDs -> tokens\n",
    "vocab = tokenizer.get_vocab()\n",
    "id_to_token = {v: k for k, v in vocab.items()}\n",
    "\n",
    "def strip_special(token: str) -> str:\n",
    "    \"\"\"\n",
    "    Removes special SentencePiece characters like '▁' from the start of tokens.\n",
    "    \"\"\"\n",
    "    return token.lstrip(\"▁\")\n",
    "\n",
    "def starts_with_letter(token: str, letter: str) -> bool:\n",
    "    \"\"\"\n",
    "    Returns True if 'token' (after removing special chars) starts with the given letter.\n",
    "    \"\"\"\n",
    "    # If equal to one special token, return False\n",
    "    if token == '▁':\n",
    "        return False\n",
    "    # Punctuation is ok\n",
    "    if token[0] == '▁' and len(token) == 2 and token[1] in string.punctuation:\n",
    "        return True\n",
    "    # Split the token by '▁' and check each sub-word\n",
    "    for sub_word in token.split('▁')[1:]:\n",
    "        if sub_word and sub_word[0].lower() != letter:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def middle_of_the_word(token: str) -> bool:\n",
    "    \"\"\"\n",
    "    Returns True if the token does not start with special character.\n",
    "    \"\"\"\n",
    "    return '▁' not in token\n",
    "\n",
    "def top_k_top_p_filtering(logits, top_k=50, top_p=0.9):\n",
    "    \"\"\"\n",
    "    Filters a distribution of logits using top-k and nucleus (top-p) filtering.\n",
    "    Sets probabilities of tokens outside the top-k or top-p to -inf.\n",
    "    \"\"\"\n",
    "    # Apply top-k\n",
    "    if top_k > 0:\n",
    "        # Get top_k indices\n",
    "        values_to_keep, _ = torch.topk(logits, top_k)\n",
    "        min_value_to_keep = values_to_keep[-1]\n",
    "        logits[logits < min_value_to_keep] = float('-inf')\n",
    "    \n",
    "    # Apply top-p (nucleus) filtering\n",
    "    sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
    "    cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "    # Mask out tokens beyond top_p\n",
    "    sorted_indices_to_remove = sorted_indices[cumulative_probs > top_p]\n",
    "    logits[sorted_indices_to_remove] = float('-inf')\n",
    "    \n",
    "    return logits\n",
    "\n",
    "def get_candidates(prefix: str, letter: str, top_k_val=50, top_p_val=0.9):\n",
    "    \"\"\"\n",
    "    Get candidate tokens (string, probability) for the next position,\n",
    "    filtered by top-k/top-p, then by first-letter constraint.\n",
    "    \"\"\"\n",
    "    input_ids = tokenizer(prefix, return_tensors='pt')['input_ids'].to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids)\n",
    "    \n",
    "    next_logits = outputs.logits[0, -1, :]\n",
    "    \n",
    "    # Apply top-k / top-p filtering\n",
    "    filtered_logits = top_k_top_p_filtering(next_logits.clone(),\n",
    "                                           top_k=top_k_val,\n",
    "                                           top_p=top_p_val)\n",
    "    probs = F.softmax(filtered_logits, dim=-1)\n",
    "    \n",
    "    # Collect valid candidates\n",
    "    candidates = []\n",
    "    for token_id in range(probs.shape[0]):\n",
    "        p = probs[token_id].item()\n",
    "        if p > 0:\n",
    "            token_str = id_to_token[token_id]\n",
    "            if middle_of_the_word(token_str) or starts_with_letter(token_str, letter):\n",
    "                candidates.append((token_str, p))\n",
    "    \n",
    "    # Sort descending by probability\n",
    "    candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "    return candidates\n",
    "\n",
    "def backtrack_generation(\n",
    "    prefix: str, \n",
    "    letter: str,\n",
    "    depth: int,\n",
    "    max_depth: int,\n",
    "    used_tokens: set,\n",
    "    tree: dict\n",
    "):\n",
    "    \"\"\"\n",
    "    Recursive function that tries to append one token at a time.\n",
    "    If we cannot find a valid token (dead end), we backtrack.\n",
    "\n",
    "    :param prefix: Current text.\n",
    "    :param letter: The designated letter for each next token.\n",
    "    :param depth: Current recursion depth (number of tokens added so far).\n",
    "    :param max_depth: Maximum tokens to generate.\n",
    "    :param used_tokens: A set of tokens we have used so far (for repetition avoidance).\n",
    "    :param tree: The nested dictionary representing the generation tree.\n",
    "    :return: Completed string if successful, or None if no solution found.\n",
    "    \"\"\"\n",
    "    # If we've reached a sentence terminator, you could choose to stop here as success:\n",
    "    if any(prefix.endswith(p) for p in ['.', '!', '?']):\n",
    "        return prefix  # success\n",
    "    \n",
    "    if depth >= max_depth:\n",
    "        # Reached maximum length\n",
    "        return prefix  # success - or None if you require punctuation end\n",
    "    \n",
    "    # Gather next candidates\n",
    "    candidates = get_candidates(prefix, letter, top_k_val=30, top_p_val=0.99)\n",
    "    # Optionally filter out tokens we've used (simple repetition avoidance)\n",
    "    filtered = [(t, p) for (t, p) in candidates if t not in used_tokens]\n",
    "    \n",
    "    # Sort by probability descending\n",
    "    filtered.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    if not filtered:\n",
    "        # No valid tokens => Dead end, must backtrack\n",
    "        # Mark dead end in the tree\n",
    "        tree['__dead_end__'] = True\n",
    "        return None\n",
    "    \n",
    "    # Try each candidate\n",
    "    for token_str, prob in filtered:\n",
    "        # Extend prefix with this token\n",
    "        token = token_str.replace('▁', ' ')\n",
    "        new_prefix = prefix + token\n",
    "        \n",
    "        # Add token to used tokens to avoid repetition\n",
    "        new_used = used_tokens.copy()\n",
    "        new_used.add(token)\n",
    "        \n",
    "        # Add this token to the tree\n",
    "        tree[token_str] = {}\n",
    "        \n",
    "        # Recurse with the new prefix and updated tree\n",
    "        result = backtrack_generation(\n",
    "            prefix=new_prefix,\n",
    "            letter=letter,\n",
    "            depth=depth+1,\n",
    "            max_depth=max_depth,\n",
    "            used_tokens=new_used,\n",
    "            tree=tree[token_str]\n",
    "        )\n",
    "        \n",
    "        if result is not None:\n",
    "            # Found a valid completion from here on\n",
    "            return result\n",
    "        else:\n",
    "            # This candidate eventually led to a dead end, continue with next candidate\n",
    "            continue\n",
    "    \n",
    "    # If all candidates lead to dead ends, mark and return None\n",
    "    tree['__dead_end__'] = True\n",
    "    return None\n",
    "\n",
    "def generate_sentence_with_backtracking(prefix, max_len=15, debug_mode=False):\n",
    "    \"\"\"\n",
    "    Wrapper that calls the recursive backtracking function and collects the generation tree.\n",
    "    \n",
    "    :param prefix: The initial text prefix.\n",
    "    :param max_len: Maximum number of tokens to generate.\n",
    "    :param debug_mode: If True, stores the generation steps; else, silent.\n",
    "    :return: Completed string and the generation tree.\n",
    "    \"\"\"\n",
    "    # The letter is the first letter of the prefix (lowercased).\n",
    "    cleaned_prefix = prefix.strip()\n",
    "    if not cleaned_prefix:\n",
    "        raise ValueError(\"Prefix cannot be empty.\")\n",
    "    \n",
    "    letter = cleaned_prefix[0].lower()\n",
    "    used_tokens = set()  # to optionally avoid immediate re-use of the same token\n",
    "    tree = {}\n",
    "    \n",
    "    completed = backtrack_generation(\n",
    "        prefix=prefix,\n",
    "        letter=letter,\n",
    "        depth=0,\n",
    "        max_depth=max_len,\n",
    "        used_tokens=used_tokens,\n",
    "        tree=tree\n",
    "    )\n",
    "    \n",
    "    # If you want to ensure the final text ends with punctuation, you can add logic here:\n",
    "    if completed is not None and not any(completed.endswith(p) for p in ['.', '!', '?']):\n",
    "        # Optionally add a period or do further checks\n",
    "        completed += \".\"\n",
    "    \n",
    "    return completed, tree\n",
    "\n",
    "def print_tree(d, indent=\"\", last=True):\n",
    "    \"\"\"\n",
    "    Recursively prints a nested dictionary in a tree-like format.\n",
    "    \n",
    "    :param d: The nested dictionary.\n",
    "    :param indent: The indentation string (used in recursion).\n",
    "    :param last: Boolean indicating if this is the last child.\n",
    "    \"\"\"\n",
    "    # Handle the root case where d is empty\n",
    "    if not d:\n",
    "        return\n",
    "    \n",
    "    keys = list(d.keys())\n",
    "    for i, key in enumerate(keys):\n",
    "        is_last = i == (len(keys) - 1)\n",
    "        connector = \"└── \" if is_last else \"├── \"\n",
    "        print(indent + connector + key)\n",
    "        if isinstance(d[key], dict):\n",
    "            extension = \"    \" if is_last else \"│   \"\n",
    "            print_tree(d[key], indent + extension, is_last)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# EXAMPLE USAGE\n",
    "# -------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    start_txts = [\n",
    "        \"Obowiązuje on od\",\n",
    "        \"Został zrodzony ze\",\n",
    "        \"Po pierwsze, projekt\",\n",
    "        \"Po Panthers przejechali\",\n",
    "        \"Duze dwusuwowe diesle\",\n",
    "        \"Niestety, nikt nie\",\n",
    "        \"Pani poseł, proszę\",\n",
    "        \"Proszę państwa, po\",\n",
    "        \"Proszę pana posła\"\n",
    "    ]\n",
    "    \n",
    "    for start_txt in start_txts:\n",
    "        print(f\"=== Generating for prefix: '{start_txt}' ===\")\n",
    "        # Generate sentence and collect the generation tree\n",
    "        completion, generation_tree = generate_sentence_with_backtracking(\n",
    "            start_txt, \n",
    "            max_len=15, \n",
    "            debug_mode=False  # debug_mode is now handled via the tree\n",
    "        )\n",
    "        print(f\"FINAL COMPLETION: '{completion}'\\n\")\n",
    "        \n",
    "        # Optionally, print the generation tree\n",
    "        print(\"Generation Tree:\")\n",
    "        print_tree(generation_tree)\n",
    "        print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hallucination_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
