{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading model: eryk-mazus/polka-1.1b\n",
      "[INFO] Using device: cuda:0\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 344.00 MiB. GPU 0 has a total capacity of 9.78 GiB of which 2.31 MiB is free. Including non-PyTorch memory, this process has 9.78 GiB memory in use. Of the allocated memory 8.63 GiB is allocated by PyTorch, and 6.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_qa_pairs, evaluate_model, LanguageModel\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Inicjalizacja modelu\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m handler \u001b[38;5;241m=\u001b[39m \u001b[43mLanguageModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Zależnie od implementacji wewnątrz utils\u001b[39;00m\n",
      "File \u001b[0;32m/pio/scratch/1/i317214/language-models/lab_2/../utils.py:32\u001b[0m, in \u001b[0;36mLanguageModel.__init__\u001b[0;34m(self, model_name, device)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mresize_token_embeddings(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer))\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Move model to device (GPU if available)\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Make sure model is in eval mode\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m/pio/scratch/1/i317214/miniconda/envs/hallucination_detection/lib/python3.11/site-packages/transformers/modeling_utils.py:3157\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   3153\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3154\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3155\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3156\u001b[0m         )\n\u001b[0;32m-> 3157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/pio/scratch/1/i317214/miniconda/envs/hallucination_detection/lib/python3.11/site-packages/torch/nn/modules/module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/pio/scratch/1/i317214/miniconda/envs/hallucination_detection/lib/python3.11/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/pio/scratch/1/i317214/miniconda/envs/hallucination_detection/lib/python3.11/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/pio/scratch/1/i317214/miniconda/envs/hallucination_detection/lib/python3.11/site-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m/pio/scratch/1/i317214/miniconda/envs/hallucination_detection/lib/python3.11/site-packages/torch/nn/modules/module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1321\u001b[0m             device,\n\u001b[1;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1323\u001b[0m             non_blocking,\n\u001b[1;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1325\u001b[0m         )\n\u001b[0;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 344.00 MiB. GPU 0 has a total capacity of 9.78 GiB of which 2.31 MiB is free. Including non-PyTorch memory, this process has 9.78 GiB memory in use. Of the allocated memory 8.63 GiB is allocated by PyTorch, and 6.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Zakładamy, że nasz \"utils.py\" jest w katalogu nadrzędnym:\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils import load_qa_pairs, evaluate_model, LanguageModel\n",
    "\n",
    "# Inicjalizacja modelu\n",
    "handler = LanguageModel()  # Zależnie od implementacji wewnątrz utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens starting with 'p': 17891\n",
      "Sample tokens (up to 30): ['▁storm', '▁akt', '▁своего', '▁lange', '▁aunque', '▁After', '▁proven', '▁Zwe', '▁del', '▁inhab', '▁band', '▁pkt', '▁Life', '▁chron', '▁Gemeins', '▁fasc', '▁om', '▁nada', '▁rescue', '▁revert', '▁Shakespeare', '▁Deb', '▁Kat', '▁Email', '▁ly', '▁verf', '▁cle', '▁adult', '▁story', '▁strik']\n"
     ]
    }
   ],
   "source": [
    "def get_allowed_tokens_for_letter(letter: str, tokenizer):\n",
    "    \"\"\"\n",
    "    Returns a list of all tokens in the tokenizer's vocabulary \n",
    "    that start with the given letter (or its uppercase version).\n",
    "    \n",
    "    :param letter: The letter we want tokens to start with (e.g. 'p').\n",
    "    :param tokenizer: The tokenizer (with a .vocab or .get_vocab() method).\n",
    "    :param lowercase: If True, also matches tokens that start with the uppercase version.\n",
    "    :return: A list of tokens (strings) that match the criterion.\n",
    "    \"\"\"\n",
    "    allowed_tokens = []\n",
    "    allowed_ids = []\n",
    "    \n",
    "    # We assume 'tokenizer.get_vocab()' gives a dict {token_str: token_id}.\n",
    "    vocab_dict = tokenizer.get_vocab()\n",
    "    \n",
    "    # Check both the given letter (e.g. 'p') and an uppercase version\n",
    "    # if you want to allow 'P...' tokens as well.\n",
    "    letter_upper = letter.upper()\n",
    "    \n",
    "    for tok_str, tok_id in vocab_dict.items():\n",
    "        # Some tokens might have special characters or whitespace\n",
    "        # We'll do a simple check that the first *alphabetic* character is our letter\n",
    "        # but we can adapt or simplify as needed.\n",
    "        \n",
    "        if not tok_str:\n",
    "            continue\n",
    "        \n",
    "        # If the very first character is letter or letter_upper\n",
    "        # or if you want to skip special tokens like <s>, <pad>, etc.\n",
    "        \n",
    "        # Strip any leading special chars like 'Ġ' in some tokenizers\n",
    "        # but this depends on the exact tokenizer you're using.\n",
    "        # We'll do a naive approach for demonstration:\n",
    "        \n",
    "        clean_tok = tok_str.lstrip(\"Ġ\")  # remove possible Byte-Level BPE leading\n",
    "        if not clean_tok:\n",
    "            continue\n",
    "        \n",
    "        first_char = clean_tok[0]\n",
    "        second_char = clean_tok[1] if len(clean_tok) > 1 else \"\"\n",
    "        \n",
    "        # check if the first character is the letter we're looking for or \"_\"\n",
    "        # if first_char != \"▁\" or second_char.lower() == letter.lower():\n",
    "        #     allowed_tokens.append(tok_str)\n",
    "        #     allowed_ids.append(tok_id)\n",
    "        if first_char == \"▁\" or first_char.lower() == letter.lower():\n",
    "            allowed_tokens.append(tok_str)\n",
    "            allowed_ids.append(tok_id)\n",
    "    \n",
    "    return allowed_tokens, allowed_ids\n",
    "\n",
    "# Example usage: let's see some tokens that start with 'p'\n",
    "allowed_tokens_for_p, _ = get_allowed_tokens_for_letter('p', handler.tokenizer)\n",
    "print(f\"Number of tokens starting with 'p': {len(allowed_tokens_for_p)}\")\n",
    "print(\"Sample tokens (up to 30):\", allowed_tokens_for_p[:30])\n",
    "# save allowed tokens to file\n",
    "# with open('allowed_tokens_for_p.txt', 'w') as f:\n",
    "#     for token in allowed_tokens_for_p:\n",
    "#         f.write(f'\"{token}\"' + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all tokens from model dictionary to file\n",
    "# with open('all_tokens.txt', 'w') as f:\n",
    "#     for token in handler.tokenizer.get_vocab().keys():\n",
    "#         f.write(f'\"{token}\"' + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PREFIX: 'Obowiązuje on od'\n",
      "'▁Movie', '▁somehow', '▁реки', '▁nuovo', 'Other', '▁z▁w', '▁Prop', '▁miasta', '▁svo', '▁Pri'\n",
      "ALLOWED LETTER: 'o'\n",
      "COMPLETION: snuririririririririririririri\n",
      "============================================================\n",
      "============================================================\n",
      "PREFIX: 'Został zrodzony ze'\n",
      "'▁doch', '▁eigh', '▁heavily', '▁Види', '▁arbeit', '▁dov', '▁dispar', '▁functionality', '▁lookup', '▁zák'\n",
      "ALLOWED LETTER: 'z'\n",
      "COMPLETION: chavavchavavchavavchavavchavav\n",
      "============================================================\n",
      "============================================================\n",
      "PREFIX: 'Po pierwsze, projekt'\n",
      "'▁score', '▁grounds', '▁Luke', '▁gen', '▁nothing', 'proof', '▁zat', '▁rot', '▁мене', '▁degree'\n",
      "ALLOWED LETTER: 'p'\n",
      "COMPLETION: rotkekekekekekekekekekekekekeke\n",
      "============================================================\n",
      "============================================================\n",
      "PREFIX: 'Po Panthers przejechali'\n",
      "'▁Prem', '▁ad', '▁allocation', '▁statunitense', '▁dużo▁', '▁San', '▁Dit', '▁towards', '▁кораб', '▁witness'\n",
      "ALLOWED LETTER: 'p'\n",
      "COMPLETION: Dalit  Dalit  Dalit  Dal\n",
      "============================================================\n",
      "============================================================\n",
      "PREFIX: 'Duze dwusuwowe diesle'\n",
      "'▁сооб', '▁behaviour', '▁argued', '▁Mau', '▁recher', '▁GR', '▁htt', '▁Mrs', '▁indep', '▁interval'\n",
      "ALLOWED LETTER: 'd'\n",
      "COMPLETION: Minininininininininininininin\n",
      "============================================================\n",
      "============================================================\n",
      "PREFIX: 'Niestety, nikt nie'\n",
      "'▁well', '▁watched', '▁persist', '▁Albert', '▁Dort', '▁Nas', '▁lamp', '▁poly', '▁Koch', '▁reject'\n",
      "ALLOWED LETTER: 'n'\n",
      "COMPLETION: KochasKochasKochasKochasKochas\n",
      "============================================================\n",
      "============================================================\n",
      "PREFIX: 'Pani poseł, proszę'\n",
      "'▁Latin', '▁Gran', '▁vital', 'Py', '▁fueron', '▁Ter', '▁сай', '▁cav', '▁sowie', '▁mem'\n",
      "ALLOWED LETTER: 'p'\n",
      "COMPLETION: cvvvvvvvvvvvvvv\n",
      "============================================================\n",
      "============================================================\n",
      "PREFIX: 'Proszę państwa, po'\n",
      "'▁Num', '▁vm', '▁championnat', '▁extrem', '▁Still', '▁Military', '▁bereits', '▁compte', '▁сай', '▁involving'\n",
      "ALLOWED LETTER: 'p'\n",
      "COMPLETION: charynatarynatarynatarynatarynatarynatarynat\n",
      "============================================================\n",
      "============================================================\n",
      "PREFIX: 'Proszę pana posła'\n",
      "'▁зу', '▁forec', '▁secretary', '▁carte', '▁au', '▁proc.▁', '▁und', '▁Assembly', '▁встре', '▁president'\n",
      "ALLOWED LETTER: 'p'\n",
      "COMPLETION: .   .   .   .   .\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Suppose we have some sentence prefixes from your example:\n",
    "prefixes = [\n",
    "    \"Obowiązuje on od\",\n",
    "    \"Został zrodzony ze\",\n",
    "    \"Po pierwsze, projekt\",\n",
    "    \"Po Panthers przejechali\",\n",
    "    \"Duze dwusuwowe diesle\",\n",
    "    \"Niestety, nikt nie\",\n",
    "    \"Pani poseł, proszę\",\n",
    "    \"Proszę państwa, po\",\n",
    "    \"Proszę pana posła\",\n",
    "]\n",
    "\n",
    "# We'll complete each prefix, forcing words to start with the letter \n",
    "# deduced from the last token's first letter or something similar.\n",
    "# For demonstration, let's choose the last word from each prefix,\n",
    "# take its first letter, build the allowed token list, and generate.\n",
    "\n",
    "for pref in prefixes:\n",
    "    # Extract the last word\n",
    "    last_word = pref.strip().split()[-1]\n",
    "    # We'll assume we want that last word's first letter\n",
    "    letter = last_word[0].lower()  # e.g. \"posła\" -> 'p'\n",
    "    \n",
    "    # Build the allowed tokens\n",
    "    allowed_tokens, allowed_ids = get_allowed_tokens_for_letter(letter, handler.tokenizer)\n",
    "    # choose randomly 100 allowed_tokens\n",
    "    allowed_tokens = random.sample(allowed_tokens, 10)\n",
    "    \n",
    "    # Generate text with constraints\n",
    "    # We'll keep temperature=1.0 for variety, set max_new_tokens=15 for short completions\n",
    "    completion = handler.generate_text_with_allowed_tokens(\n",
    "        prompt=pref,\n",
    "        allowed_ids=allowed_ids,\n",
    "        allowed_tokens=allowed_tokens,\n",
    "        max_new_tokens=15,\n",
    "        temperature=0.3\n",
    "    )\n",
    "    \n",
    "    # Print the result\n",
    "    print(\"=\"*60)\n",
    "    print(f\"PREFIX: '{pref}'\")\n",
    "    print(\", \".join([f\"'{token}'\" for token in allowed_tokens])) # allowed_tokens\n",
    "    print(f\"ALLOWED LETTER: '{letter}'\")\n",
    "    print(f\"COMPLETION: {completion}\")\n",
    "    print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pio/scratch/1/i317214/miniconda/envs/hallucination_detection/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from torch.nn import functional as F\n",
    "import random\n",
    "\n",
    "model_name = 'eryk-mazus/polka-1.1b'  # Updated model name to match initialization\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating completion for prefix: 'Pani poseł, proszę'\n",
      "PREFIX: 'Pani poseł, proszę'\n",
      "   [op] 0.0135\n",
      "   [pamięta]* 0.0131\n",
      "   [przekaz] 0.0081\n",
      "   [nap] 0.0066\n",
      "   [wys] 0.0051\n",
      "   [poinform] 0.0050\n",
      "   [,] 0.0050\n",
      "   [zapyta] 0.0044\n",
      "   [zab] 0.0031\n",
      "   [się w] 0.0030\n",
      "============================================================\n",
      "PREFIX: 'Pani poseł, proszępamięta'\n",
      "   [ć, że] 0.0463\n",
      "   [?] 0.0213\n",
      "   [,]* 0.0166\n",
      "   [, że] 0.0154\n",
      "   [.] 0.0119\n",
      "   [!] 0.0053\n",
      "   [:] 0.0043\n",
      "   [?\\n] 0.0041\n",
      "   [-] 0.0027\n",
      "   [, co] 0.0019\n",
      "============================================================\n",
      "PREFIX: 'Pani poseł, proszępamięta,'\n",
      "   [może] 0.0058\n",
      "   [op] 0.0028\n",
      "   [mów] 0.0025\n",
      "   [pon] 0.0021\n",
      "   [mam] 0.0019\n",
      "   [tr] 0.0018\n",
      "   [pr] 0.0018\n",
      "   [zn]* 0.0017\n",
      "   [nap] 0.0017\n",
      "   [pro] 0.0017\n",
      "============================================================\n",
      "PREFIX: 'Pani poseł, proszępamięta,zn'\n",
      "   [asz]* 0.4456\n",
      "   [isz] 0.0442\n",
      "   [ies] 0.0146\n",
      "   [ika] 0.0079\n",
      "   [osi] 0.0071\n",
      "   [iew] 0.0070\n",
      "   [ów z] 0.0026\n",
      "   [ów w] 0.0023\n",
      "   [ien] 0.0020\n",
      "   [anego] 0.0020\n",
      "============================================================\n",
      "PREFIX: 'Pani poseł, proszępamięta,znasz'\n",
      "   [przepis] 0.0170\n",
      "   [dobrze] 0.0124\n",
      "   [,] 0.0098\n",
      "   [?] 0.0089\n",
      "   [prawo]* 0.0077\n",
      "   [swoje] 0.0073\n",
      "   [wyn] 0.0055\n",
      "   [poję] 0.0046\n",
      "   [tre] 0.0042\n",
      "   [dokład] 0.0032\n",
      "============================================================\n",
      "PREFIX: 'Pani poseł, proszępamięta,znaszprawo'\n",
      "   [?]* 0.1579\n",
      "   [,] 0.1185\n",
      "   [?\\n] 0.0539\n",
      "   [.] 0.0361\n",
      "   [!] 0.0110\n",
      "   [\\n] 0.0104\n",
      "   [-] 0.0095\n",
      "   [???] 0.0045\n",
      "   [konst] 0.0045\n",
      "   [podat] 0.0044\n",
      "============================================================\n",
      "PREFIX: 'Pani poseł, proszępamięta,znaszprawo?'\n",
      "   [-] 0.0328\n",
      "   [!] 0.0300\n",
      "   [Czy] 0.0110\n",
      "   [\\] 0.0062\n",
      "   [!\\n] 0.0058\n",
      "   [Pro] 0.0044\n",
      "   [J]* 0.0041\n",
      "   [Prz] 0.0040\n",
      "   […] 0.0030\n",
      "   [–] 0.0029\n",
      "============================================================\n",
      "PREFIX: 'Pani poseł, proszępamięta,znaszprawo?J'\n",
      "   [aka] 0.0940\n",
      "   [ako] 0.0430\n",
      "   [esz] 0.0415\n",
      "   [AK] 0.0258\n",
      "   [eden] 0.0142\n",
      "   [a w] 0.0128\n",
      "   [.]* 0.0054\n",
      "   [a p] 0.0045\n",
      "   [edy] 0.0043\n",
      "   [ó] 0.0037\n",
      "============================================================\n",
      "PREFIX: 'Pani poseł, proszępamięta,znaszprawo?J.'\n",
      "   [J]* 0.0206\n",
      "   [Ś] 0.0109\n",
      "   [St] 0.0088\n",
      "   [Ch] 0.0075\n",
      "   [H] 0.0070\n",
      "   [Now] 0.0060\n",
      "   [Cz] 0.0054\n",
      "   [Pi] 0.0043\n",
      "   [Sz] 0.0041\n",
      "   [Le] 0.0031\n",
      "============================================================\n",
      "PREFIX: 'Pani poseł, proszępamięta,znaszprawo?J.J'\n",
      "   [.] 0.1834\n",
      "   [are]* 0.0858\n",
      "   [. K] 0.0237\n",
      "   [ure] 0.0181\n",
      "   [urg] 0.0150\n",
      "   [anus] 0.0135\n",
      "   [ank] 0.0085\n",
      "   [ark] 0.0084\n",
      "   [.\\n] 0.0083\n",
      "   [\\n] 0.0065\n",
      "============================================================\n",
      "PREFIX: 'Pani poseł, proszępamięta,znaszprawo?J.Jare'\n",
      "   [cka] 0.0521\n",
      "   [czka]* 0.0441\n",
      "   [cki] 0.0058\n",
      "   [cko] 0.0041\n",
      "   [k] 0.0038\n",
      "   [kc] 0.0026\n",
      "   [kow] 0.0022\n",
      "   [k (] 0.0021\n",
      "   [man] 0.0019\n",
      "   [ckiego] 0.0019\n",
      "============================================================\n",
      "PREFIX: 'Pani poseł, proszępamięta,znaszprawo?J.Jareczka'\n",
      "   [:]* 0.1057\n",
      "   [\\n] 0.0583\n",
      "   [,] 0.0557\n",
      "   [-] 0.0183\n",
      "   [\\nP] 0.0168\n",
      "   [2] 0.0128\n",
      "   [.] 0.0111\n",
      "   [\\] 0.0073\n",
      "   [1] 0.0069\n",
      "   [:\\n] 0.0048\n",
      "============================================================\n",
      "PREFIX: 'Pani poseł, proszępamięta,znaszprawo?J.Jareczka:'\n",
      "   [J] 0.0064\n",
      "   [„] 0.0044\n",
      "   [Prze]* 0.0043\n",
      "   [Pro] 0.0041\n",
      "   [Prz] 0.0040\n",
      "   [PiS] 0.0035\n",
      "   [Mam] 0.0031\n",
      "   [By] 0.0028\n",
      "   [1] 0.0027\n",
      "   [Czy] 0.0024\n",
      "============================================================\n",
      "PREFIX: 'Pani poseł, proszępamięta,znaszprawo?J.Jareczka:Prze'\n",
      "   [pr] 0.2290\n",
      "   [pisy] 0.1306\n",
      "   [kaz]* 0.0561\n",
      "   [ciw] 0.0462\n",
      "   [pro] 0.0149\n",
      "   [każ] 0.0118\n",
      "   [kon] 0.0105\n",
      "   [łom] 0.0078\n",
      "   [cięt] 0.0074\n",
      "   [ks] 0.0071\n",
      "============================================================\n",
      "PREFIX: 'Pani poseł, proszępamięta,znaszprawo?J.Jareczka:Przekaz'\n",
      "   [ałem] 0.2198\n",
      "   [yw]* 0.0648\n",
      "   [ujemy] 0.0372\n",
      "   [ałam] 0.0164\n",
      "   [,] 0.0020\n",
      "   [uje się] 0.0019\n",
      "   [anie] 0.0019\n",
      "   [ałe] 0.0018\n",
      "   [ał się] 0.0017\n",
      "   [:] 0.0011\n",
      "============================================================\n",
      "PREFIX: 'Pani poseł, proszępamięta,znaszprawo?J.Jareczka:Przekazyw'\n",
      "   [ałem] 0.0304\n",
      "   [ałam] 0.0089\n",
      "   [anie]* 0.0065\n",
      "   [ane przez] 0.0022\n",
      "   [ane z] 0.0016\n",
      "   [ałe] 0.0006\n",
      "   [ark] 0.0003\n",
      "   [aliśmy] 0.0003\n",
      "   [ał się] 0.0003\n",
      "   [alis] 0.0003\n",
      "============================================================\n",
      "PREFIX: 'Pani poseł, proszępamięta,znaszprawo?J.Jareczka:Przekazywanie'\n",
      "   [danych] 0.0189\n",
      "   [dot] 0.0108\n",
      "   [medi] 0.0093\n",
      "   [pomocy]* 0.0091\n",
      "   [br] 0.0071\n",
      "   [ul] 0.0047\n",
      "   [państw] 0.0045\n",
      "   [mand] 0.0043\n",
      "   [gr] 0.0032\n",
      "   [ws] 0.0031\n",
      "============================================================\n",
      "PREFIX: 'Pani poseł, proszępamięta,znaszprawo?J.Jareczka:Przekazywaniepomocy'\n",
      "   [zag]* 0.0442\n",
      "   [,] 0.0140\n",
      "   [społecz] 0.0103\n",
      "   [inn] 0.0077\n",
      "   [finans] 0.0051\n",
      "   [psych] 0.0043\n",
      "   [\\n] 0.0039\n",
      "   [soc] 0.0035\n",
      "   [.] 0.0030\n",
      "   [zdrow] 0.0029\n",
      "============================================================\n",
      "PREFIX: 'Pani poseł, proszępamięta,znaszprawo?J.Jareczka:Przekazywaniepomocyzag'\n",
      "   [roż] 0.0239\n",
      "   [ospodar]* 0.0058\n",
      "   [raż] 0.0020\n",
      "   [rab] 0.0008\n",
      "   [war] 0.0007\n",
      "   [reg] 0.0004\n",
      "   [łos] 0.0004\n",
      "   [ryw] 0.0004\n",
      "   [roz] 0.0003\n",
      "   [łod] 0.0002\n",
      "============================================================\n",
      "PREFIX: 'Pani poseł, proszępamięta,znaszprawo?J.Jareczka:Przekazywaniepomocyzagospodar'\n",
      "   [owaniu]* 0.1656\n",
      "   [stw] 0.0284\n",
      "   [owan] 0.0220\n",
      "   [zen] 0.0098\n",
      "   [zenia] 0.0073\n",
      "   [owanie w] 0.0053\n",
      "   [owanym] 0.0041\n",
      "   [owaną] 0.0027\n",
      "   [czym] 0.0024\n",
      "   [owanie z] 0.0019\n",
      "============================================================\n",
      "PREFIX: 'Pani poseł, proszępamięta,znaszprawo?J.Jareczka:Przekazywaniepomocyzagospodarowaniu'\n",
      "   [pr] 0.0143\n",
      "   [gr] 0.0124\n",
      "   [,]* 0.0114\n",
      "   [.] 0.0093\n",
      "   [-] 0.0070\n",
      "   [prz] 0.0064\n",
      "   [\\n] 0.0055\n",
      "   [zag] 0.0053\n",
      "   [praw] 0.0037\n",
      "   [pow] 0.0035\n",
      "============================================================\n",
      "PREFIX: 'Pani poseł, proszępamięta,znaszprawo?J.Jareczka:Przekazywaniepomocyzagospodarowaniu,'\n",
      "   [pr] 0.0166\n",
      "   [któ] 0.0135\n",
      "   [przy] 0.0107\n",
      "   [czyli] 0.0066\n",
      "   [dla]* 0.0058\n",
      "   [prz] 0.0055\n",
      "   [oraz] 0.0051\n",
      "   [organiz] 0.0046\n",
      "   [pom] 0.0046\n",
      "   [przez] 0.0045\n",
      "============================================================\n",
      "PREFIX: 'Pani poseł, proszępamięta,znaszprawo?J.Jareczka:Przekazywaniepomocyzagospodarowaniu,dla'\n",
      "   [czego]* 0.0584\n",
      "   [pos] 0.0093\n",
      "   [pr] 0.0087\n",
      "   [przed] 0.0075\n",
      "   [mał] 0.0056\n",
      "   [pro] 0.0052\n",
      "   [mieszkańców] 0.0051\n",
      "   [wszystkich] 0.0046\n",
      "   [któ] 0.0046\n",
      "   [czeg] 0.0042\n",
      "============================================================\n",
      "PREFIX: 'Pani poseł, proszępamięta,znaszprawo?J.Jareczka:Przekazywaniepomocyzagospodarowaniu,dlaczego'\n",
      "   [?] 0.0875\n",
      "   [,]* 0.0096\n",
      "   [?\\n] 0.0084\n",
      "   [tr] 0.0060\n",
      "   [.] 0.0026\n",
      "   [więc] 0.0022\n",
      "   [powin] 0.0020\n",
      "   [mam] 0.0018\n",
      "   [-] 0.0018\n",
      "   [???] 0.0015\n",
      "============================================================\n",
      "PREFIX: 'Pani poseł, proszępamięta,znaszprawo?J.Jareczka:Przekazywaniepomocyzagospodarowaniu,dlaczego,'\n",
      "   [dla] 0.0673\n",
      "   [kto] 0.0183\n",
      "   [kiedy] 0.0129\n",
      "   [jaka] 0.0128\n",
      "   [gdy] 0.0069\n",
      "   [pr] 0.0059\n",
      "   [jeśli]* 0.0051\n",
      "   [oraz] 0.0045\n",
      "   [pro] 0.0041\n",
      "   [przy] 0.0040\n",
      "============================================================\n",
      "PREFIX: 'Pani poseł, proszępamięta,znaszprawo?J.Jareczka:Przekazywaniepomocyzagospodarowaniu,dlaczego,jeśli'\n",
      "   [,]* 0.1297\n",
      "   [?] 0.0663\n",
      "   [?\\n] 0.0124\n",
      "   [.] 0.0090\n",
      "   [-] 0.0049\n",
      "   [?,] 0.0043\n",
      "   [tr] 0.0043\n",
      "   [\\n] 0.0036\n",
      "   [???] 0.0021\n",
      "   [potrzeb] 0.0020\n",
      "============================================================\n",
      "PREFIX: 'Pani poseł, proszępamięta,znaszprawo?J.Jareczka:Przekazywaniepomocyzagospodarowaniu,dlaczego,jeśli,'\n",
      "   [dla] 0.0789\n",
      "   [kto] 0.0268\n",
      "   [kiedy]* 0.0184\n",
      "   [jaka] 0.0160\n",
      "   [gdy] 0.0069\n",
      "   [jeśli] 0.0061\n",
      "   [przy] 0.0055\n",
      "   [czego] 0.0042\n",
      "   [pr] 0.0042\n",
      "   [pro] 0.0034\n",
      "============================================================\n",
      "PREFIX: 'Pani poseł, proszępamięta,znaszprawo?J.Jareczka:Przekazywaniepomocyzagospodarowaniu,dlaczego,jeśli,kiedy'\n",
      "   [?]* 0.2847\n",
      "   [,] 0.2771\n",
      "   [?\\n] 0.0572\n",
      "   [.] 0.0355\n",
      "   [?,] 0.0276\n",
      "   [\\n] 0.0167\n",
      "   [-] 0.0092\n",
      "   [,\\n] 0.0049\n",
      "   [.\\n] 0.0048\n",
      "   [???] 0.0043\n",
      "============================================================\n",
      "PREFIX: 'Pani poseł, proszępamięta,znaszprawo?J.Jareczka:Przekazywaniepomocyzagospodarowaniu,dlaczego,jeśli,kiedy?'\n",
      "   [J] 0.0511\n",
      "   [-] 0.0197\n",
      "   [Pro] 0.0129\n",
      "   [1] 0.0098\n",
      "   [2] 0.0085\n",
      "   [Czy]* 0.0085\n",
      "   [\\] 0.0078\n",
      "   [Pr] 0.0074\n",
      "   [[] 0.0062\n",
      "   [Roz] 0.0056\n",
      "============================================================\n",
      "PREFIX: 'Pani poseł, proszępamięta,znaszprawo?J.Jareczka:Przekazywaniepomocyzagospodarowaniu,dlaczego,jeśli,kiedy?Czy'\n",
      "   [tr]* 0.0051\n",
      "   [pos] 0.0036\n",
      "   [prawo] 0.0032\n",
      "   [ist] 0.0030\n",
      "   [nap] 0.0028\n",
      "   [może] 0.0028\n",
      "   [pomoc] 0.0025\n",
      "   [mam] 0.0023\n",
      "   [wsp] 0.0022\n",
      "   [op] 0.0022\n",
      "============================================================\n",
      "\n",
      "################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def best_k(prefix, K=10):\n",
    "    input_ids = tokenizer(prefix, return_tensors='pt')['input_ids'].to(device)    \n",
    "    output = model(input_ids=input_ids)\n",
    "    next_token_logits = output.logits[0, -1, :]\n",
    "    probs = F.softmax(next_token_logits, dim=-1)\n",
    "    d = {}\n",
    "    for i in range(probs.shape[0]):\n",
    "        tok_str = tokenizer.decode(i).strip()\n",
    "        # Remove leading special characters (e.g., 'Ġ' in some tokenizers)\n",
    "        # tok_str_clean = tok_str.lstrip(\"Ġ\")\n",
    "        tok_str_clean = tok_str\n",
    "        # Check if the token has an odd number of letters\n",
    "        if (len(tok_str_clean) > 0 and tok_str_clean[0] != '▁') or \\\n",
    "            (len(tok_str_clean) > 1 and tok_str_clean[0] == '▁' and tok_str_clean[1] == 'p'):\n",
    "            d[tok_str] = probs[i].item()\n",
    "    \n",
    "    # Sort tokens by probability in descending order and select top K\n",
    "    sorted_tokens = sorted(d.items(), key=lambda x: x[1], reverse=True)\n",
    "    return sorted_tokens[:K]\n",
    "\n",
    "def sample_from_pairs(pairs): \n",
    "    tokens  = [p[0] for p in pairs]    \n",
    "    weights = [p[1] for p in pairs]\n",
    "    if not tokens:\n",
    "        return \"\"  # Return empty string if no valid tokens\n",
    "    return random.choices(tokens, weights=weights, k=1)[0]\n",
    "\n",
    "# Example prefixes\n",
    "start_txts = [\n",
    "    \"Pani poseł, proszę\"\n",
    "]\n",
    "\n",
    "def sample_demo(N, txt):\n",
    "    for i in range(N):\n",
    "        d = best_k(txt)\n",
    "        print(f\"PREFIX: '{txt}'\")\n",
    "        if not d:\n",
    "            print(\"   [INFO] No allowed tokens with odd number of letters found.\")\n",
    "            print(\"=\"*60)\n",
    "            break\n",
    "        next_token = sample_from_pairs(d)\n",
    "        for t, p in d:\n",
    "            star = '*' if t == next_token else ''\n",
    "            print(f\"   [{t}]{star} {p:.4f}\")\n",
    "        txt += next_token\n",
    "        print(\"=\"*60)\n",
    "\n",
    "# Run the demo for each prefix\n",
    "for start_txt in start_txts:\n",
    "    print(f\"Generating completion for prefix: '{start_txt}'\")\n",
    "    sample_demo(30, start_txt)  # Generate 3 tokens for each prefix\n",
    "    print(\"\\n\" + \"#\"*80 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hallucination_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
