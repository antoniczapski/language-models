{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pio/scratch/1/i317214/miniconda/envs/hallucination_detection/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from torch.nn import functional as F\n",
    "import random\n",
    "\n",
    "model_name = 'eryk-mazus/polka-1.1b'  # Updated model name to match initialization\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating completion for prefix: 'Obowiązuje on od'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPLETION: 'Obowiązuje on odroczone w odstępstwie od okresów wskazanych odprawione od og'\n",
      "\n",
      "Generating completion for prefix: 'Został zrodzony ze'\n",
      "COMPLETION: 'Został zrodzony ze złamanego źródła wiersza to źródło się, które zostało wybrane w źród'\n",
      "\n",
      "Generating completion for prefix: 'Po pierwsze, projekt'\n",
      "COMPLETION: 'Po pierwsze, projektowanie podnosi poczucie pewnego prestiżenia, co przyciąga przedsiębiorstwa'\n",
      "\n",
      "Generating completion for prefix: 'Po Panthers przejechali'\n",
      "COMPLETION: 'Po Panthers przejechali przez parkingu przy panieńskich pucharach <0xF0>\\nPo panther prze'\n",
      "\n",
      "Generating completion for prefix: 'Duze dwusuwowe diesle'\n",
      "COMPLETION: 'Duze dwusuwowe diesle dostepne w dobrejach dla dealerem dla dealeria dacia duster'\n",
      "\n",
      "Generating completion for prefix: 'Niestety, nikt nie'\n",
      "COMPLETION: 'Niestety, nikt nie nastrudnił się na naszych nieszczeg...\\nPrzepięknie utrzym'\n",
      "\n",
      "Generating completion for prefix: 'Pani poseł, proszę'\n",
      "COMPLETION: 'Pani poseł, proszę przestać się przepracować, procentowanie pensacji posła w parłach'\n",
      "\n",
      "Generating completion for prefix: 'Proszę państwa, po'\n",
      "COMPLETION: 'Proszę państwa, po pierwszych próbach przerwania pracy pojechałem pod przerwanie'\n",
      "\n",
      "Generating completion for prefix: 'Proszę pana posła'\n",
      "COMPLETION: 'Proszę pana posła, że pan przestać się posłowie przynieście panie posłowie prz'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vocab = tokenizer.get_vocab()\n",
    "# print(vocab)\n",
    "vocab_switch_key = {v: k for k, v in vocab.items()}\n",
    "\n",
    "def best_k(prefix, K=10):\n",
    "    letter = prefix[0].lower()\n",
    "    input_ids = tokenizer(prefix, return_tensors='pt')['input_ids'].to(device)    \n",
    "    output = model(input_ids=input_ids)\n",
    "    next_token_logits = output.logits[0, -1, :]\n",
    "    probs = F.softmax(next_token_logits, dim=-1)\n",
    "    d = {}\n",
    "    # tokenizer.get_vocab()\n",
    "    for i in range(probs.shape[0]):\n",
    "        tok_str = tokenizer.decode(i, skip_special_tokens=True)\n",
    "        tok_str = vocab_switch_key.get(i,\"\")\n",
    "        # print(f\"'{tok_str}'\")\n",
    "        # Remove leading special characters (e.g., 'Ġ' in some tokenizers)\n",
    "        # tok_str_clean = tok_str.lstrip(\"Ġ\")\n",
    "        tok_str_clean = tok_str\n",
    "        # Check if the token has an odd number of letters\n",
    "        if (len(tok_str_clean) > 3 and tok_str_clean[0] != '▁') or \\\n",
    "            (len(tok_str_clean) > 1 and tok_str_clean[0] == '▁' and tok_str_clean[1] == letter):\n",
    "            d[tok_str.replace('▁', ' ')] = probs[i].item()\n",
    "            # print(f\"asdasdasdsad---#{tok_str}#\")\n",
    "        # if i>1000:\n",
    "        #     break\n",
    "    \n",
    "    # Sort tokens by probability in descending order and select top K\n",
    "    sorted_tokens = sorted(d.items(), key=lambda x: x[1], reverse=True)\n",
    "    return sorted_tokens[:K]\n",
    "\n",
    "def sample_from_pairs(pairs): \n",
    "    tokens  = [p[0] for p in pairs]    \n",
    "    weights = [p[1] for p in pairs]\n",
    "    if not tokens:\n",
    "        return \"\"  # Return empty string if no valid tokens\n",
    "    return random.choices(tokens, weights=weights, k=1)[0]\n",
    "\n",
    "# Example prefixes\n",
    "start_txts = \\\n",
    "\"\"\"Obowiązuje on od\n",
    "Został zrodzony ze\n",
    "Po pierwsze, projekt\n",
    "Po Panthers przejechali\n",
    "Duze dwusuwowe diesle\n",
    "Niestety, nikt nie\n",
    "Pani poseł, proszę\n",
    "Proszę państwa, po\n",
    "Proszę pana posła\"\"\".split('\\n')\n",
    "\n",
    "def sample_demo(N, txt):\n",
    "    for i in range(N):\n",
    "        d = best_k(txt)\n",
    "        # print(f\"PREFIX: '{txt}'\")\n",
    "        if not d:\n",
    "            # print(\"   [INFO] No allowed tokens with odd number of letters found.\")\n",
    "            # print(\"=\"*60)\n",
    "            break\n",
    "        next_token = sample_from_pairs(d)\n",
    "        for t, p in d:\n",
    "            star = '*' if t == next_token else ''\n",
    "            # print(f\"   [{t}]{star} {p:.4f}\")\n",
    "        txt += next_token\n",
    "        # print(\"=\"*60)\n",
    "    print(f\"COMPLETION: '{txt}'\\n\")\n",
    "\n",
    "# Run the demo for each prefix\n",
    "for start_txt in start_txts:\n",
    "    print(f\"Generating completion for prefix: '{start_txt}'\")\n",
    "    sample_demo(15, start_txt)  # Generate 3 tokens for each prefix\n",
    "    # print(\"\\n\" + \"#\"*80 + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hallucination_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
