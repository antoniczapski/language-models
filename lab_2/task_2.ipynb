{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model 'eryk-mazus/polka-1.1b' loaded on cuda.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# 1. Load model\n",
    "model_name = 'eryk-mazus/polka-1.1b'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"[INFO] Model '{model_name}' loaded on {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Riddles:\n",
      "1. kobieta podróżująca środkiem transportu, np. samolotem, pociągiem, statkiem\n",
      "2. emocjonalne uczucie łączące dwie osoby, oparte na zaufaniu, szacunku, trosce i oddaniu\n",
      "3. największe miasto w Polsce\n",
      "\n",
      "Possible Answers: ['pasażerka', 'miłość', 'warszawa']\n"
     ]
    }
   ],
   "source": [
    "# 2. Suppose we have some riddles and a known set of valid answers.\n",
    "\n",
    "riddles = [\n",
    "    \"kobieta podróżująca środkiem transportu, np. samolotem, pociągiem, statkiem\",\n",
    "    \"emocjonalne uczucie łączące dwie osoby, oparte na zaufaniu, szacunku, trosce i oddaniu\",\n",
    "    \"największe miasto w Polsce\",\n",
    "]\n",
    "\n",
    "answer_set = [\n",
    "    \"pasażerka\",\n",
    "    \"miłość\",\n",
    "    \"warszawa\",\n",
    "    # ... you can add more known answers if needed\n",
    "]\n",
    "\n",
    "print(\"Riddles:\")\n",
    "for idx, r in enumerate(riddles, 1):\n",
    "    print(f\"{idx}. {r}\")\n",
    "print(\"\\nPossible Answers:\", answer_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      " Zagadka: kobieta podróżująca środkiem transportu, np. samolotem, pociągiem, statkiem\n",
      "Odpowiedź: pasażerka\n",
      "\n",
      "Zagadka: emocjonalne uczucie łączące dwie osoby, oparte na zaufaniu, szacunku, trosce i oddaniu\n",
      "Odpowiedź: miłość\n",
      "\n",
      "Zagadka: największe miasto w Polsce\n",
      "Odpowiedź: \n",
      "\n",
      "Generated Answer: warszawa\n"
     ]
    }
   ],
   "source": [
    "def build_few_shot_prompt(riddle_text: str, examples=None) -> str:\n",
    "    \"\"\"\n",
    "    Creates a few-shot prompt with riddle -> answer pairs,\n",
    "    then ends with the new riddle for which we want an answer.\n",
    "    \"\"\"\n",
    "    if examples is None:\n",
    "        examples = [\n",
    "            # Minimal example from your instructions:\n",
    "            (\"kobieta podróżująca środkiem transportu, np. samolotem, pociągiem, statkiem\", \"pasażerka\"),\n",
    "            (\"emocjonalne uczucie łączące dwie osoby, oparte na zaufaniu, szacunku, trosce i oddaniu\", \"miłość\")\n",
    "        ]\n",
    "    prompt = \"\"\n",
    "    for ex_riddle, ex_answer in examples:\n",
    "        prompt += f\"Zagadka: {ex_riddle}\\nOdpowiedź: {ex_answer}\\n\\n\"\n",
    "    # Add the new riddle\n",
    "    prompt += f\"Zagadka: {riddle_text}\\nOdpowiedź:\"\n",
    "    return prompt\n",
    "\n",
    "def constrained_generate_answer(\n",
    "    prompt: str,\n",
    "    answer_set: list[str],\n",
    "    max_new_tokens: int = 20,\n",
    "    temperature: float = 1.0\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Iteratively generates tokens from 'prompt', but only allows partial sequences\n",
    "    that remain a prefix of at least one valid answer in 'answer_set'.\n",
    "    \n",
    "    Once we match a full answer from answer_set, we stop.\n",
    "    The final answer is the portion after 'Odpowiedź:'.\n",
    "    \"\"\"\n",
    "    # 1) Encode the prompt\n",
    "    input_ids = tokenizer(prompt, return_tensors='pt')['input_ids'].to(device)\n",
    "    \n",
    "    generated = input_ids.clone()  # we keep track of the growing sequence\n",
    "    \n",
    "    # We'll store the partial decoded answer (the portion after 'Odpowiedź:') as we go\n",
    "    # Each iteration, we decode everything after the prompt, see if it's a prefix\n",
    "    # of any valid answer\n",
    "    start_len = input_ids.shape[1]  # length of the entire prompt\n",
    "    eos_token_id = tokenizer.eos_token_id\n",
    "    partial_answer = \"\"\n",
    "\n",
    "    def is_prefix_of_answer(s: str) -> bool:\n",
    "        return any(ans.startswith(s) for ans in answer_set)\n",
    "\n",
    "    def is_full_answer(s: str) -> bool:\n",
    "        return s in answer_set\n",
    "\n",
    "    # 2) Iterative generation\n",
    "    for step in range(max_new_tokens):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(generated)\n",
    "            logits = outputs.logits[:, -1, :]  # shape: [1, vocab_size]\n",
    "        \n",
    "        # We'll build new logits by setting -inf for tokens that\n",
    "        # don't keep partial_answer as prefix of any valid answer\n",
    "        new_logits = torch.full_like(logits, float('-inf'))\n",
    "        \n",
    "        # We try each possible vocab token and see if it leads to a valid prefix\n",
    "        for token_id in range(logits.shape[1]):\n",
    "            # skip special tokens if you want\n",
    "            if token_id == eos_token_id:\n",
    "                # Potentially allow EOS if partial_answer is already full?\n",
    "                # we'll skip it for now\n",
    "                continue\n",
    "\n",
    "            # Hypothesize appending this token\n",
    "            cand_ids = torch.cat([generated[0], torch.tensor([token_id]).to(device)])\n",
    "            cand_text = tokenizer.decode(cand_ids, skip_special_tokens=True)\n",
    "            # The newly generated portion is everything after the prompt\n",
    "            new_part = cand_text[len(prompt):].strip()\n",
    "\n",
    "            if new_part:\n",
    "                # Only keep this token if new_part is prefix of at least one answer\n",
    "                if is_prefix_of_answer(new_part):\n",
    "                    new_logits[0, token_id] = logits[0, token_id]\n",
    "            else:\n",
    "                # if new_part is empty, it's also valid as a prefix\n",
    "                new_logits[0, token_id] = logits[0, token_id]\n",
    "\n",
    "        # Apply temperature\n",
    "        if temperature > 0:\n",
    "            new_logits = new_logits / temperature\n",
    "            probs = F.softmax(new_logits, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            # Greedy\n",
    "            next_token = torch.argmax(new_logits, dim=-1, keepdim=True)\n",
    "\n",
    "        # Append\n",
    "        generated = torch.cat([generated, next_token], dim=1)\n",
    "\n",
    "        # Decode partial answer\n",
    "        full_text = tokenizer.decode(generated[0], skip_special_tokens=True)\n",
    "        partial_answer = full_text[len(prompt):].strip()\n",
    "\n",
    "        # If partial_answer is a complete valid answer, we stop\n",
    "        if is_full_answer(partial_answer):\n",
    "            break\n",
    "\n",
    "    return partial_answer\n",
    "\n",
    "# Quick test\n",
    "test_prompt = build_few_shot_prompt(\"największe miasto w Polsce\")\n",
    "print(\"Prompt:\\n\", test_prompt, \"\\n\")\n",
    "\n",
    "ans = constrained_generate_answer(test_prompt, [\"pasażerka\",\"miłość\",\"warszawa\"], max_new_tokens=10, temperature=0.7)\n",
    "print(\"Generated Answer:\", ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Riddle: kobieta podróżująca środkiem transportu, np. samolotem, pociągiem, statkiem\n",
      "Answer: pasażerka\n",
      "--------------------------------------------------\n",
      "Riddle: emocjonalne uczucie łączące dwie osoby, oparte na zaufaniu, szacunku, trosce i oddaniu\n",
      "Answer: miłość\n",
      "--------------------------------------------------\n",
      "Riddle: największe miasto w Polsce\n",
      "Answer: warszawa\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "few_shot_examples = [\n",
    "    (\"kobieta podróżująca środkiem transportu, np. samolotem, pociągiem, statkiem\", \"pasażerka\"),\n",
    "    (\"emocjonalne uczucie łączące dwie osoby, oparte na zaufaniu, szacunku, trosce i oddaniu\", \"miłość\"),\n",
    "]\n",
    "\n",
    "for riddle_text in riddles:\n",
    "    # Build a few-shot prompt\n",
    "    prompt = build_few_shot_prompt(riddle_text, examples=few_shot_examples)\n",
    "    \n",
    "    # Generate constrained answer\n",
    "    answer = constrained_generate_answer(prompt, answer_set, max_new_tokens=10, temperature=0.7)\n",
    "    \n",
    "    print(\"Riddle:\", riddle_text)\n",
    "    print(\"Answer:\", answer)\n",
    "    print(\"-\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8085 answers from plwiktionary_definitions_clean.txt\n",
      "Sample: ['księga', 'płot', 'styczność', 'przypuszczenie', 'barszcz', 'spekulacja', 'zanieczyszczenie', 'wit', 'opel', 'codzienność', 'temperatura', 'wszechświat', 'spółgłoska', 'substancja', 'dziennikarz', 'bastion', 'kopiec', 'bigos', 'stwierdzenie', 'egzemplarz', 'światełko', 'brykiet', 'cytadela', 'pomoc', 'wiersz', 'mięta', 'elektron', 'felietonista', 'infolinia', 'kwestionariusz', 'pani', 'zaleta', 'montaż', 'rondo', 'sprzedawca', 'wyraz', 'obiektywność', 'kontrolowanie', 'darczyńca', 'bunkier', 'sekret', 'aktywizowanie', 'przyimek', 'szyja', 'ranek', 'amplituda', 'okładka', 'spichrz', 'marazm', 'czystość']\n"
     ]
    }
   ],
   "source": [
    "# open data/plwiktionary_definitions_clean.txt\n",
    "with open('data/zagadki/plwiktionary_definitions_clean.txt', 'r') as file:\n",
    "    final_answer_set = set([line.split()[0].lower() for line in file.readlines()])\n",
    "print(\"Loaded\", len(final_answer_set), \"answers from plwiktionary_definitions_clean.txt\")\n",
    "print(\"Sample:\", list(final_answer_set)[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1993 riddles from zagadki_do_testow_clean.txt\n",
      "Sample: ('manuskrypt', 'rękopiśmienny tekst lub dokument, niepublikowany drukiem.')\n",
      "('wesołość', 'stan emocjonalny charakteryzujący się radością, życzliwością i łatwością w wywoływaniu uśmiechu.')\n",
      "('legenda', 'opowieść lub historia przekazywana ustnie lub pisaną, często ze zmyślonymi lub niepotwierdzonymi elementami, która ma na celu przekazanie ważnych wartości, nauk, czy też przekonań.')\n",
      "('antysemityzm', 'postawa, przekonania lub działania mające na celu dyskryminację, prześladowanie lub nienawiść wobec żydów jako grupy etnicznej, religijnej lub kulturowej.')\n",
      "('filmowanie', 'proces rejestracji obrazu i dźwięku za pomocą kamery w celu tworzenia filmu.')\n"
     ]
    }
   ],
   "source": [
    "# zagadki_do_testow_clean.txt\n",
    "with open('data/zagadki/zagadki_do_testow_clean.txt', 'r') as file:\n",
    "    final_riddles = {line.split()[0]:' '.join(line.split()[2:]) for line in file.readlines()}\n",
    "\n",
    "print(\"Loaded\", len(final_riddles), \"riddles from zagadki_do_testow_clean.txt\")\n",
    "print(\"Sample:\", '\\n'.join(map(str,list(final_riddles.items())[:5])))\n",
    "\n",
    "true_answers = []\n",
    "riddles_txt = []\n",
    "for riddle, answer in final_riddles.items():\n",
    "    riddles_txt.append(riddle)\n",
    "    true_answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [07:13<11:54:50, 433.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Riddle: rękopiśmienny tekst lub dokument, niepublikowany drukiem.\n",
      "Answer: ['list', 'pamiętnik', 'notatka']\n",
      "Correct Answer: manuskrypt\n",
      "Correct? False\n",
      "Score: 0/1 - 0.00%\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [17:42<14:56:06, 548.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Riddle: stan emocjonalny charakteryzujący się radością, życzliwością i łatwością w wywoływaniu uśmiechu.\n",
      "Answer: ['optymizm', 'euforia', 'euforia']\n",
      "Correct Answer: wesołość\n",
      "Correct? False\n",
      "Score: 0/2 - 0.00%\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [26:42<14:40:19, 544.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Riddle: opowieść lub historia przekazywana ustnie lub pisaną, często ze zmyślonymi lub niepotwierdzonymi elementami, która ma na celu przekazanie ważnych wartości, nauk, czy też przekonań.\n",
      "Answer: ['baśń', 'baśń', 'baśń']\n",
      "Correct Answer: legenda\n",
      "Correct? False\n",
      "Score: 0/3 - 0.00%\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [42:07<18:31:28, 694.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Riddle: postawa, przekonania lub działania mające na celu dyskryminację, prześladowanie lub nienawiść wobec żydów jako grupy etnicznej, religijnej lub kulturowej.\n",
      "Answer: ['antysemityzm', 'antysemityzm', 'antysemityzm']\n",
      "Correct Answer: antysemityzm\n",
      "Correct? True\n",
      "Score: 1/4 - 25.00%\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [48:12<15:11:56, 575.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Riddle: proces rejestracji obrazu i dźwięku za pomocą kamery w celu tworzenia filmu.\n",
      "Answer: ['film', 'rejestracja', 'film']\n",
      "Correct Answer: filmowanie\n",
      "Correct? False\n",
      "Score: 1/5 - 20.00%\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [1:00:55<16:41:50, 639.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Riddle: aktywność polegająca na zanurzaniu się pod wodę, zazwyczaj za pomocą sprzętu oddechowego, w celu eksploracji podwodnego świata.\n",
      "Answer: ['płetw', 'nur', 'nur']\n",
      "Correct Answer: nurkowanie\n",
      "Correct? False\n",
      "Score: 1/6 - 16.67%\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [1:19:42<20:38:02, 798.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Riddle: treść, wypowiedź lub zachowanie pozbawione sensu, logicznego uzasadnienia lub sensownego znaczenia.\n",
      "Answer: ['deklaracja', 'przyzwoitość', 'tande']\n",
      "Correct Answer: nonsens\n",
      "Correct? False\n",
      "Score: 1/7 - 14.29%\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [1:29:01<18:28:08, 722.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Riddle: formalne odmówienie zgody na podjęcie określonej decyzji lub działania, stosowane w celu zablokowania lub opóźnienia procesu decyzyjnego.\n",
      "Answer: ['rezygnacja', 'odmowa', 'zarząd']\n",
      "Correct Answer: weto\n",
      "Correct? False\n",
      "Score: 1/8 - 12.50%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "few_shot_examples = [\n",
    "    (\"kobieta podróżująca środkiem transportu, np. samolotem, pociągiem, statkiem\", \"pasażerka\"),\n",
    "    (\"emocjonalne uczucie łączące dwie osoby, oparte na zaufaniu, szacunku, trosce i oddaniu\", \"miłość\"),\n",
    "    (\"suchą częścią powierzchni ziemi niezależną od akwenów wodnych.\",\"ląd\"),\n",
    "    (\"nieuprawnione i bezprawne wtargnięcie na czyjeś tereny lub do cudzego pomieszczenia w celu kradzieży lub popełnienia innych przestępstw.\",\"włamanie\"),\n",
    "    (\"potoczne określenie osoby nadużywającej alkoholu.\",\"pijak\"),\n",
    "    (\"proces testowania, badania lub wdrażania konkretnego rozwiązania, pomysłu lub projektu w praktyce.\",\"pilotaż\"),\n",
    "    (\"koncepcja związana z hinduizmem, buddyzmem i dżinizmem, mówiąca o zależności między działaniami jednostki a ich konsekwencjami w obecnym lub przyszłym życiu.\",\"karma\"),\n",
    "    (\"osoba zajmująca się badaniem i interpretacją przeszłości na podstawie dostępnych źródeł historycznych. może zajmować się różnymi epokami, wydarzeniami lub postaciami historycznymi.\",\"historyk\"),\n",
    "    (\"naśladowanie lub próba odtworzenia zachowania, stylu, charakterystyk lub cech innych osób lub rzeczy.\",\"imitacja\"),\n",
    "    (\"dodatek do ubioru zakładany na szyję lub ramiona, mający różne kształty, wzory i materiały.\",\"szal\")\n",
    "]\n",
    "from tqdm import tqdm\n",
    "total_score = 0\n",
    "iter = 0\n",
    "# create empty file\n",
    "open('data/zagadki/results.txt', 'w').close()\n",
    "for true_answer, riddle_text in tqdm(list(final_riddles.items())[:100]):\n",
    "    iter += 1\n",
    "    # Build a few-shot prompt\n",
    "    prompt = build_few_shot_prompt(riddle_text, examples=few_shot_examples)\n",
    "    \n",
    "    # Generate constrained answers\n",
    "    answers = []\n",
    "    for _ in range(3):\n",
    "        answer = constrained_generate_answer(prompt, final_answer_set, max_new_tokens=10, temperature=0.7)\n",
    "        answers.append(answer)\n",
    "\n",
    "    correct = true_answer in answers\n",
    "    total_score += correct\n",
    "    print(\"Riddle:\", riddle_text)\n",
    "    print(\"Answer:\", answers)\n",
    "    print(\"Correct Answer:\", true_answer)\n",
    "    print(\"Correct?\", correct)\n",
    "    print(f\"Score: {total_score}/{iter} - {total_score/iter:.2%}\")\n",
    "    print(\"-\"*50)\n",
    "    \n",
    "    logs = \"Riddle: \" + riddle_text + \"\\n\" + \"Answer: \" + str(answers) + \"\\n\" + \"Correct Answer: \" + true_answer + \"\\n\" + \"Correct? \" + str(correct) + \"\\n\" + \"Score: \" + str(total_score) + \"/\" + str(iter) + \" - \" + str(total_score/iter) + \"\\n\" + \"-\"*50 + \"\\n\"\n",
    "    with open('data/zagadki/results.txt', 'a') as file:\n",
    "        file.write(logs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Score: 23.23333333333333/100 - 23.23%\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "with open('task_2_results.txt', 'r') as file:\n",
    "    content = '\\n'.join(file.readlines())\n",
    "    \n",
    "riddles = content.split('--------------------------------------------------')\n",
    "# Riddle: rękopiśmienny tekst lub dokument, niepublikowany drukiem.\n",
    "# Answer: ['pieśń', 'pieśń', 'list', 'tek', 'apel']\n",
    "# Correct Answer: manuskrypt\n",
    "# Correct? False\n",
    "# Score: 0/1 - 0.0\n",
    "score = 0\n",
    "for riddle in riddles:\n",
    "    if not riddle:\n",
    "        print(riddle)\n",
    "        continue\n",
    "    # get answer\n",
    "    # print(riddle)\n",
    "    answer = riddle.split('Answer: ')[1].split('\\n')[0]\n",
    "    if not answer or answer == '[]':\n",
    "        print(riddle)\n",
    "        continue\n",
    "    correct_answer = riddle.split('Correct Answer: ')[1].split('\\n')[0]\n",
    "    for i, ans in enumerate(ast.literal_eval(answer)):\n",
    "        if correct_answer in ans:\n",
    "            score += 1/(i+1)\n",
    "            break\n",
    "print(f\"Final Score: {score}/{len(riddles)} - {score/len(riddles):.2%}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hallucination_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
